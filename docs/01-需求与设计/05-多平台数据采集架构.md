# å¤šå¹³å°æ•°æ®é‡‡é›†æ¶æ„è®¾è®¡

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**æ–‡æ¡£ç›®æ ‡**: è¯¦ç»†è®¾è®¡ä»å¤šä¸ªå¹³å°é‡‡é›†Web3é¡¹ç›®ä¿¡æ¯çš„æŠ€æœ¯æ–¹æ¡ˆ  
**æ ¸å¿ƒç†å¿µ**: ä¸åŒå¹³å°ç‰¹æ€§ä¸åŒï¼Œéœ€è¦å®šåˆ¶åŒ–çš„é‡‡é›†ç­–ç•¥  
**æ›´æ–°æ—¶é—´**: 2025-10-04

---

## ğŸ—ºï¸ æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å¤šå¹³å°æ•°æ®é‡‡é›†æ€»æ§ (Multi-Source Orchestrator)      â”‚
â”‚                                                               â”‚
â”‚  - ä»»åŠ¡è°ƒåº¦ï¼ˆCeleryï¼‰                                         â”‚
â”‚  - ä¼˜å…ˆçº§é˜Ÿåˆ—ç®¡ç†                                             â”‚
â”‚  - é”™è¯¯é‡è¯•æœºåˆ¶                                               â”‚
â”‚  - æ•°æ®å»é‡ä¸å½’ä¸€åŒ–                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   æ–‡å­—å¹³å°              ç¤¾äº¤å¹³å°              è§†é¢‘å¹³å°
        â”‚                     â”‚                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Twitter/X      â”‚   â”‚ Telegram        â”‚   â”‚ YouTube        â”‚
â”‚ Medium         â”‚   â”‚ Discord         â”‚   â”‚ TikTok         â”‚
â”‚ Mirror.xyz     â”‚   â”‚ Reddit          â”‚   â”‚ Bilibili       â”‚
â”‚ Substack       â”‚   â”‚ Farcaster       â”‚   â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š å¹³å°ä¼˜å…ˆçº§çŸ©é˜µ

### ç¬¬ä¸€æ¢¯é˜Ÿï¼ˆä¼˜å…ˆå®ç° - Week 1-2ï¼‰

| å¹³å° | ç±»å‹ | ä¼˜å…ˆçº§ | æ—¥å‡ä¿¡æ¯é‡ | å®æ—¶æ€§ | æŠ€æœ¯éš¾åº¦ |
|------|------|--------|-----------|--------|----------|
| **Twitter/X** | ç¤¾äº¤ | â­â­â­â­â­ | 5000+ æ¨æ–‡ | å®æ—¶ | ä¸­ç­‰ |
| **Telegram** | ç¤¾äº¤ | â­â­â­â­â­ | 3000+ æ¶ˆæ¯ | å®æ—¶ | ä¸­ç­‰ |
| **Discord** | ç¤¾äº¤ | â­â­â­â­ | 2000+ æ¶ˆæ¯ | å®æ—¶ | è¾ƒé«˜ |
| **Medium** | æ–‡å­— | â­â­â­â­ | 200+ æ–‡ç«  | å°æ—¶çº§ | ä½ |

### ç¬¬äºŒæ¢¯é˜Ÿï¼ˆWeek 3-4ï¼‰

| å¹³å° | ç±»å‹ | ä¼˜å…ˆçº§ | æ—¥å‡ä¿¡æ¯é‡ | å®æ—¶æ€§ | æŠ€æœ¯éš¾åº¦ |
|------|------|--------|-----------|--------|----------|
| **Reddit** | ç¤¾äº¤ | â­â­â­ | 1000+ å¸–å­ | å°æ—¶çº§ | ä½ |
| **YouTube** | è§†é¢‘ | â­â­â­ | 50+ è§†é¢‘ | å¤©çº§ | ä¸­ç­‰ |
| **Mirror.xyz** | æ–‡å­— | â­â­â­ | 50+ æ–‡ç«  | å¤©çº§ | ä½ |

### ç¬¬ä¸‰æ¢¯é˜Ÿï¼ˆWeek 5+ï¼‰

| å¹³å° | ç±»å‹ | ä¼˜å…ˆçº§ | æ—¥å‡ä¿¡æ¯é‡ | å®æ—¶æ€§ | æŠ€æœ¯éš¾åº¦ |
|------|------|--------|-----------|--------|----------|
| **æŠ–éŸ³/TikTok** | è§†é¢‘ | â­â­ | 500+ è§†é¢‘ | å®æ—¶ | é«˜ |
| **å°çº¢ä¹¦** | å›¾æ–‡ | â­â­ | 300+ ç¬”è®° | å°æ—¶çº§ | ä¸­ç­‰ |
| **Bç«™** | è§†é¢‘ | â­â­ | 100+ è§†é¢‘ | å¤©çº§ | ä¸­ç­‰ |
| **Farcaster** | ç¤¾äº¤ | â­â­ | 200+ æ¶ˆæ¯ | å®æ—¶ | ä¸­ç­‰ |

---

## ğŸ¦ å¹³å°ä¸€: Twitter/X

### 1.1 å¹³å°ç‰¹ç‚¹

**ä¸ºä»€ä¹ˆé‡è¦**:
- âœ… Web3ä¿¡æ¯ä¼ æ’­æœ€å¿«çš„å¹³å°
- âœ… KOLå¯†é›†ï¼Œæ„è§é¢†è¢–å½±å“åŠ›å¤§
- âœ… é¡¹ç›®å®˜æ–¹é¦–å‘åœ°
- âœ… è¯é¢˜çƒ­åº¦æœ€å®¹æ˜“è§‚å¯Ÿ

**æ•°æ®ç‰¹ç‚¹**:
- çŸ­æ–‡æœ¬ï¼ˆ280å­—ç¬¦ï¼‰
- é«˜äº’åŠ¨æ€§ï¼ˆè½¬å‘ã€ç‚¹èµã€è¯„è®ºï¼‰
- å®æ—¶æ€§å¼ºï¼ˆç§’çº§æ›´æ–°ï¼‰
- ç¤¾äº¤å›¾è°±æ˜ç¡®

### 1.2 é‡‡é›†ç­–ç•¥

#### ç­–ç•¥ä¸€ï¼šå…³é”®è¯ç›‘æ§

**ç›®æ ‡**: æ•è·æ‰€æœ‰æåŠæœªå‘å¸é¡¹ç›®çš„æ¨æ–‡

**å…³é”®è¯åº“**:
```python
KEYWORDS = {
    # é¡¹ç›®é˜¶æ®µ
    "presale", "fair launch", "stealth launch", "soft launch",
    "testnet", "mainnet launch", "beta launch",
    
    # èèµ„ç›¸å…³
    "seed round", "series A", "raised $", "funding announcement",
    "backed by", "investment from",
    
    # ä»£å¸ç›¸å…³
    "token launch", "TGE", "IDO", "ICO", "IEO", "airdrop",
    "token sale", "whitelist", "allocation",
    
    # é¡¹ç›®ç‰¹å¾
    "no token yet", "æœªå‘å¸", "pre-token", "points system",
    "early stage", "stealth mode",
    
    # æŠ€æœ¯æ ‡ç­¾
    "DeFi", "NFT", "GameFi", "SocialFi", "Layer2", "zkSync",
    "Optimistic Rollup", "Zero Knowledge",
}
```

**æŸ¥è¯¢æ„å»º**:
```python
# ç¤ºä¾‹æŸ¥è¯¢
query = """
(presale OR "fair launch" OR "no token yet" OR airdrop) 
(DeFi OR NFT OR GameFi OR Layer2)
-is:retweet 
lang:en
"""

# é«˜çº§ç­›é€‰
filters = {
    "min_followers": 1000,      # å‘æ¨äººæœ€ä½ç²‰ä¸æ•°
    "min_engagement": 10,        # æœ€ä½äº’åŠ¨æ•°ï¼ˆè½¬å‘+ç‚¹èµï¼‰
    "exclude_verified_only": False,  # ä¸æ’é™¤æœªè®¤è¯è´¦å·
}
```

#### ç­–ç•¥äºŒï¼šKOLè¿½è¸ª

**ç›®æ ‡**: ç›‘æ§é¡¶çº§åŠ å¯†KOLçš„æ¯æ¡æ¨æ–‡å’Œäº’åŠ¨

**KOLåˆ†çº§ä½“ç³»**:

```python
TIER_1_KOLS = [
    # è¡Œä¸šé¢†è¢–ï¼ˆç²‰ä¸>1Mï¼‰
    "VitalikButerin",        # ä»¥å¤ªåŠåˆ›å§‹äºº
    "cz_binance",            # Binanceåˆ›å§‹äºº
    "brian_armstrong",       # Coinbase CEO
    "SBF_FTX",               # FTXåˆ›å§‹äººï¼ˆå†å²å‚è€ƒï¼‰
    
    # é¡¶çº§æŠ•èµ„äººï¼ˆç²‰ä¸>500Kï¼‰
    "APompliano",            # Pomp
    "RaoulGMI",              # Real Vision
    "novogratz",             # Galaxy Digital
]

TIER_2_KOLS = [
    # èµ„æ·±åˆ†æå¸ˆï¼ˆç²‰ä¸>100Kï¼‰
    "TheCryptoLark",
    "CryptoCred",
    "inversebrah",
    "CryptoWendyO",
    "IamCryptoWolf",
    
    # æŠ€æœ¯ä¸“å®¶
    "hasufl",                # MEVä¸“å®¶
    "0xMaki",                # DeFi
    "DCinvestor",            # ä»¥å¤ªåŠ
]

TIER_3_KOLS = [
    # æ–°å…´KOLï¼ˆç²‰ä¸>10Kï¼‰
    "0xSisyphus",
    "Dynamo_Patrick",
    "DefiIgnas",
    # ... 100+ KOLs
]
```

**è¿½è¸ªé€»è¾‘**:
```python
def track_kol_activity(username: str, tier: int):
    """è¿½è¸ªKOLæ´»åŠ¨"""
    
    # 1. è·å–åŸåˆ›æ¨æ–‡ï¼ˆæ’é™¤è½¬å‘ï¼‰
    tweets = get_user_tweets(
        username=username,
        exclude=["retweets"],
        max_results=10
    )
    
    # 2. è·å–ç‚¹èµçš„æ¨æ–‡ï¼ˆå‘ç°å…³æ³¨ç‚¹ï¼‰
    liked_tweets = get_user_likes(
        username=username,
        max_results=20
    )
    
    # 3. è·å–è½¬å‘çš„æ¨æ–‡ï¼ˆå¼ºçƒˆæ¨èä¿¡å·ï¼‰
    retweeted = get_user_retweets(
        username=username,
        max_results=20
    )
    
    # æƒé‡è®¡ç®—
    for tweet in tweets:
        tweet["signal_strength"] = calculate_signal(
            is_original=True,
            author_tier=tier,
            engagement=tweet["engagement"]
        )
    
    return {
        "original": tweets,
        "liked": liked_tweets,
        "retweeted": retweeted
    }
```

#### ç­–ç•¥ä¸‰ï¼šè¯„è®ºåŒºæŒ–æ˜ï¼ˆæ ¸å¿ƒï¼ï¼‰

**ç›®æ ‡**: ä»çƒ­é—¨æ¨æ–‡çš„è¯„è®ºåŒºå‘ç°æ—©æœŸé¡¹ç›®è®¨è®º

**ä¸ºä»€ä¹ˆé‡è¦**:
- è¯„è®ºåŒºå¾€å¾€æœ‰"çŸ¥æƒ…è€…"æå‰é€éœ²ä¿¡æ¯
- ç¤¾åŒºè®¨è®ºçš„é¡¹ç›®å¾€å¾€æ˜¯çœŸå®éœ€æ±‚
- è¯„è®ºåŒºäº’åŠ¨æ•°æ®åæ˜ çœŸå®çƒ­åº¦

**æŒ–æ˜ç®—æ³•**:
```python
def mine_comment_section(tweet_id: str):
    """æŒ–æ˜è¯„è®ºåŒº"""
    
    # 1. è·å–æ‰€æœ‰è¯„è®º
    comments = get_tweet_replies(
        tweet_id=tweet_id,
        max_results=100,
        sort_by="engagement"  # æŒ‰äº’åŠ¨æ•°æ’åº
    )
    
    # 2. è¯„è®ºè´¨é‡è¿‡æ»¤
    quality_comments = []
    for comment in comments:
        score = calculate_comment_quality(comment)
        if score > 60:  # è´¨é‡é˜ˆå€¼
            quality_comments.append(comment)
    
    # 3. é¡¹ç›®æåŠæå–
    mentioned_projects = []
    for comment in quality_comments:
        projects = extract_project_mentions(comment["text"])
        
        for project in projects:
            mentioned_projects.append({
                "project_name": project,
                "mentioned_by": comment["author"],
                "author_followers": comment["author_followers"],
                "comment_likes": comment["likes"],
                "sentiment": analyze_sentiment(comment["text"]),
                "context": comment["text"][:200]
            })
    
    # 4. é¡¹ç›®çƒ­åº¦èšåˆ
    project_heatmap = aggregate_project_mentions(mentioned_projects)
    
    return project_heatmap


def calculate_comment_quality(comment: dict) -> int:
    """è®¡ç®—è¯„è®ºè´¨é‡åˆ†ï¼ˆ0-100ï¼‰"""
    
    score = 0
    
    # å› å­1: è¯„è®ºè€…ç²‰ä¸æ•°ï¼ˆ30åˆ†ï¼‰
    followers = comment["author_followers"]
    score += min(30, followers / 1000)
    
    # å› å­2: è¯„è®ºäº’åŠ¨æ•°ï¼ˆ30åˆ†ï¼‰
    engagement = comment["likes"] + comment["replies"]
    score += min(30, engagement / 10)
    
    # å› å­3: è¯„è®ºé•¿åº¦ï¼ˆ20åˆ†ï¼‰- é•¿è¯„è®ºå¾€å¾€æ›´æœ‰ä»·å€¼
    text_length = len(comment["text"])
    if 50 < text_length < 280:
        score += 20
    elif text_length >= 280:
        score += 15
    
    # å› å­4: åŒ…å«é“¾æ¥æˆ–åˆçº¦åœ°å€ï¼ˆ20åˆ†ï¼‰
    has_url = "http" in comment["text"]
    has_contract = re.match(r"0x[a-fA-F0-9]{40}", comment["text"])
    if has_url or has_contract:
        score += 20
    
    # æƒ©ç½šé¡¹: åƒåœ¾è¯„è®ºç‰¹å¾
    spam_keywords = ["follow me", "dm me", "check my profile", "100x guaranteed"]
    for keyword in spam_keywords:
        if keyword.lower() in comment["text"].lower():
            score -= 30
    
    return max(0, min(100, score))
```

#### ç­–ç•¥å››ï¼šè¯é¢˜çƒ­åº¦è¿½è¸ª

**ç›®æ ‡**: å‘ç°çªç„¶çˆ†å‘çš„è¯é¢˜å’Œhashtag

**çƒ­åº¦è®¡ç®—å…¬å¼**:
```python
def calculate_topic_heat(topic: str, time_window: int = 24) -> dict:
    """è®¡ç®—è¯é¢˜çƒ­åº¦"""
    
    # 1. è·å–æ—¶é—´çª—å£å†…çš„æåŠæ•°æ®
    mentions = get_topic_mentions(
        topic=topic,
        hours=time_window
    )
    
    # 2. åˆ†æ—¶æ®µç»Ÿè®¡
    hourly_counts = group_by_hour(mentions)
    
    # 3. è®¡ç®—å¢é•¿ç‡
    recent_hour = hourly_counts[-1]
    previous_avg = sum(hourly_counts[:-1]) / len(hourly_counts[:-1])
    growth_rate = (recent_hour - previous_avg) / previous_avg if previous_avg > 0 else 0
    
    # 4. è®¡ç®—KOLå‚ä¸åº¦
    kol_participation = count_kol_mentions(mentions)
    
    # 5. ç»¼åˆçƒ­åº¦åˆ†
    heat_score = (
        min(50, recent_hour) +                    # ç»å¯¹æ•°é‡ï¼ˆæœ€é«˜50åˆ†ï¼‰
        min(30, growth_rate * 100) +              # å¢é•¿ç‡ï¼ˆæœ€é«˜30åˆ†ï¼‰
        min(20, kol_participation * 4)            # KOLå‚ä¸ï¼ˆæœ€é«˜20åˆ†ï¼‰
    )
    
    return {
        "topic": topic,
        "heat_score": heat_score,
        "hourly_mentions": hourly_counts,
        "growth_rate": f"{growth_rate*100:.1f}%",
        "kol_count": kol_participation,
        "is_trending": heat_score > 70
    }
```

### 1.3 æ•°æ®ç»“æ„è®¾è®¡

```python
class TwitterData(BaseModel):
    """Twitteré‡‡é›†æ•°æ®æ¨¡å‹"""
    
    # åŸºç¡€ä¿¡æ¯
    tweet_id: str
    author_id: str
    author_username: str
    author_display_name: str
    
    # è´¦å·å±æ€§
    author_verified: bool
    author_followers: int
    author_following: int
    author_created_at: datetime
    
    # æ¨æ–‡å†…å®¹
    text: str
    language: str
    created_at: datetime
    
    # äº’åŠ¨æ•°æ®
    likes: int
    retweets: int
    replies: int
    quotes: int
    bookmarks: int
    impressions: Optional[int]
    
    # å®ä½“æå–
    urls: List[str]
    hashtags: List[str]
    mentions: List[str]
    cashtags: List[str]  # $BTC, $ETH
    
    # åª’ä½“
    has_media: bool
    media_types: List[str]  # photo, video, gif
    
    # å…ƒæ•°æ®
    is_reply: bool
    is_quote: bool
    replied_to_id: Optional[str]
    quoted_tweet_id: Optional[str]
    
    # åˆ†æç»“æœ
    matched_keywords: List[str]
    mentioned_projects: List[str]
    contracts_found: List[str]
    sentiment_score: Optional[float]  # -1åˆ°1
    
    # ä¿¡å·å¼ºåº¦
    signal_strength: int  # 0-100
    is_from_kol: bool
    kol_tier: Optional[int]
    
    # é‡‡é›†å…ƒä¿¡æ¯
    collected_at: datetime
    collection_method: str  # keyword_search, kol_tracking, comment_mining


class TwitterCommentData(BaseModel):
    """è¯„è®ºåŒºæ•°æ®æ¨¡å‹"""
    
    parent_tweet_id: str
    comment_id: str
    
    # è¯„è®ºè€…ä¿¡æ¯
    author_username: str
    author_followers: int
    
    # è¯„è®ºå†…å®¹
    text: str
    created_at: datetime
    
    # äº’åŠ¨æ•°æ®
    likes: int
    replies: int
    
    # æåŠçš„é¡¹ç›®
    mentioned_projects: List[ProjectMention]
    
    # è´¨é‡è¯„åˆ†
    quality_score: int  # 0-100
    
    # æƒ…æ„Ÿ
    sentiment: str  # positive, neutral, negative


class ProjectMention(BaseModel):
    """é¡¹ç›®æåŠ"""
    
    project_name: str
    confidence: float  # 0-1ï¼Œè¯†åˆ«ç½®ä¿¡åº¦
    context: str  # æåŠæ—¶çš„ä¸Šä¸‹æ–‡
    sentiment: str
    mentioned_by: str
    mention_source: str  # tweet, comment, kol_post
```

### 1.4 æŠ€æœ¯å®ç°

#### APIé€‰æ‹©

**å®˜æ–¹APIï¼ˆæ¨èï¼‰**:
```python
import tweepy

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = tweepy.Client(
    bearer_token=TWITTER_BEARER_TOKEN,
    consumer_key=TWITTER_API_KEY,
    consumer_secret=TWITTER_API_SECRET,
    access_token=TWITTER_ACCESS_TOKEN,
    access_token_secret=TWITTER_ACCESS_SECRET,
    wait_on_rate_limit=True  # è‡ªåŠ¨å¤„ç†é™æµ
)

# APIé™åˆ¶ï¼ˆV2 APIï¼‰
RATE_LIMITS = {
    "search_recent": "450æ¬¡/15åˆ†é’Ÿ",
    "user_tweets": "1500æ¬¡/15åˆ†é’Ÿ",
    "tweet_lookup": "300æ¬¡/15åˆ†é’Ÿ",
}
```

**å¤‡ç”¨æ–¹æ¡ˆï¼ˆTwitter Scraperï¼‰**:
```python
from snscrape.modules.twitter import TwitterSearchScraper

# æ— éœ€APIå¯†é’¥ï¼Œä½†ä¸ç¨³å®š
scraper = TwitterSearchScraper('crypto since:2025-01-01')
for tweet in scraper.get_items():
    process_tweet(tweet)
```

#### åçˆ¬è™«ç­–ç•¥

```python
# ç­–ç•¥1: å¤šè´¦å·è½®æ¢
accounts = [
    {"bearer_token": TOKEN_1, "last_used": None},
    {"bearer_token": TOKEN_2, "last_used": None},
    {"bearer_token": TOKEN_3, "last_used": None},
]

def get_available_client():
    """è·å–å¯ç”¨å®¢æˆ·ç«¯"""
    for account in accounts:
        if can_use(account):
            return tweepy.Client(bearer_token=account["bearer_token"])
    
    # å…¨éƒ¨é™æµï¼Œç­‰å¾…
    time.sleep(60)
    return get_available_client()


# ç­–ç•¥2: è¯·æ±‚é—´éš”
import time
import random

def rate_limited_request(func, *args, **kwargs):
    """é™æµè¯·æ±‚"""
    time.sleep(random.uniform(1, 3))  # éšæœºå»¶è¿Ÿ1-3ç§’
    return func(*args, **kwargs)


# ç­–ç•¥3: é”™è¯¯é‡è¯•
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def robust_api_call(client, method, **params):
    """å¥å£®çš„APIè°ƒç”¨"""
    try:
        return method(**params)
    except tweepy.TooManyRequests:
        logger.warning("Rate limit hit, waiting...")
        time.sleep(900)  # ç­‰15åˆ†é’Ÿ
        raise
    except tweepy.TwitterServerError:
        logger.error("Twitter server error")
        raise
```

#### é‡‡é›†ä»»åŠ¡è°ƒåº¦

```python
# Celeryå®šæ—¶ä»»åŠ¡
from celery import Celery
from celery.schedules import crontab

app = Celery('twitter_collector')

@app.task
def collect_keyword_tweets():
    """é‡‡é›†å…³é”®è¯æ¨æ–‡ - æ¯5åˆ†é’Ÿ"""
    collector = TwitterCollector()
    tweets = collector.monitor_keywords(hours=1)
    save_to_database(tweets)


@app.task
def collect_kol_tweets():
    """é‡‡é›†KOLæ¨æ–‡ - æ¯15åˆ†é’Ÿ"""
    collector = TwitterCollector()
    
    # Tier1 KOL - æ¯æ¬¡é‡‡é›†
    for kol in TIER_1_KOLS:
        tweets = collector.track_kol_tweets(kol, max_results=10)
        save_to_database(tweets)
    
    # Tier2/3 KOL - è½®è¯¢é‡‡é›†
    kol_sample = sample_kols(TIER_2_KOLS + TIER_3_KOLS, size=20)
    for kol in kol_sample:
        tweets = collector.track_kol_tweets(kol, max_results=5)
        save_to_database(tweets)


@app.task
def mine_comment_sections():
    """æŒ–æ˜è¯„è®ºåŒº - æ¯å°æ—¶"""
    
    # æ‰¾åˆ°è¿‡å»1å°æ—¶å†…é«˜äº’åŠ¨æ¨æ–‡
    hot_tweets = get_hot_tweets(
        min_engagement=100,
        hours=1
    )
    
    # æŒ–æ˜æ¯æ¡æ¨æ–‡çš„è¯„è®ºåŒº
    for tweet in hot_tweets:
        comments = mine_comment_section(tweet["tweet_id"])
        save_to_database(comments)


@app.task
def analyze_trending_topics():
    """åˆ†æçƒ­é—¨è¯é¢˜ - æ¯2å°æ—¶"""
    
    # è·å–Twitter Trending Topics
    trends = get_twitter_trends(location="Worldwide")
    
    # ç­›é€‰åŠ å¯†ç›¸å…³è¯é¢˜
    crypto_trends = filter_crypto_trends(trends)
    
    # è®¡ç®—æ¯ä¸ªè¯é¢˜çš„çƒ­åº¦
    for topic in crypto_trends:
        heat_data = calculate_topic_heat(topic)
        if heat_data["is_trending"]:
            send_alert(f"ğŸ”¥ æ–°çƒ­ç‚¹: {topic}")


# ä»»åŠ¡è°ƒåº¦é…ç½®
app.conf.beat_schedule = {
    'collect-keywords': {
        'task': 'collect_keyword_tweets',
        'schedule': 300.0,  # æ¯5åˆ†é’Ÿ
    },
    'collect-kols': {
        'task': 'collect_kol_tweets',
        'schedule': 900.0,  # æ¯15åˆ†é’Ÿ
    },
    'mine-comments': {
        'task': 'mine_comment_sections',
        'schedule': 3600.0,  # æ¯å°æ—¶
    },
    'analyze-trends': {
        'task': 'analyze_trending_topics',
        'schedule': 7200.0,  # æ¯2å°æ—¶
    },
}
```

### 1.5 æ•°æ®è´¨é‡ä¿è¯

```python
def validate_twitter_data(data: TwitterData) -> bool:
    """éªŒè¯æ•°æ®è´¨é‡"""
    
    # æ£€æŸ¥1: å¿…å¡«å­—æ®µ
    required_fields = ["tweet_id", "author_username", "text", "created_at"]
    for field in required_fields:
        if not getattr(data, field):
            return False
    
    # æ£€æŸ¥2: å»é‡
    if is_duplicate(data.tweet_id):
        return False
    
    # æ£€æŸ¥3: æ—¶æ•ˆæ€§ï¼ˆä¸æ¥å—è¶…è¿‡24å°æ—¶çš„æ•°æ®ï¼‰
    age = datetime.now() - data.created_at
    if age.total_seconds() > 86400:
        return False
    
    # æ£€æŸ¥4: åƒåœ¾è¿‡æ»¤
    if is_spam(data.text):
        return False
    
    return True


def is_spam(text: str) -> bool:
    """åƒåœ¾æ¨æ–‡æ£€æµ‹"""
    
    spam_patterns = [
        r"(follow|like|retweet) for (follow|like|retweet)",
        r"dm me for",
        r"100x guaranteed",
        r"get rich quick",
        r"pump (now|tonight|tomorrow)",
    ]
    
    for pattern in spam_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return True
    
    return False
```

### 1.6 éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**:
- âœ… èƒ½å¤Ÿæ¯5åˆ†é’Ÿé‡‡é›†å…³é”®è¯ç›¸å…³æ¨æ–‡
- âœ… èƒ½å¤Ÿè¿½è¸ª100+ KOLçš„æœ€æ–°æ¨æ–‡
- âœ… èƒ½å¤ŸæŒ–æ˜çƒ­é—¨æ¨æ–‡çš„è¯„è®ºåŒº
- âœ… èƒ½å¤Ÿè¯†åˆ«çªç„¶çˆ†å‘çš„è¯é¢˜

**æ€§èƒ½éªŒæ”¶**:
- âœ… æ—¥é‡‡é›†é‡ > 5,000æ¡æ¨æ–‡
- âœ… æ•°æ®å»¶è¿Ÿ < 10åˆ†é’Ÿ
- âœ… å»é‡å‡†ç¡®ç‡ > 95%
- âœ… APIé™æµå¤„ç†æˆåŠŸç‡ > 99%

**è´¨é‡éªŒæ”¶**:
- âœ… åƒåœ¾æ¨æ–‡è¿‡æ»¤ç‡ > 90%
- âœ… é¡¹ç›®åç§°æå–å‡†ç¡®ç‡ > 80%
- âœ… æƒ…æ„Ÿåˆ†æå‡†ç¡®ç‡ > 75%

---

## ğŸ’¬ å¹³å°äºŒ: Telegram

### 2.1 å¹³å°ç‰¹ç‚¹

**ä¸ºä»€ä¹ˆé‡è¦**:
- âœ… é¡¹ç›®å®˜æ–¹é¦–å‘æ¸ é“ï¼ˆè¶…è¿‡90%çš„é¡¹ç›®æœ‰Telegramç¾¤ï¼‰
- âœ… ç¤¾åŒºè®¨è®ºæœ€æ´»è·ƒ
- âœ… å®˜æ–¹å…¬å‘Šæœ€åŠæ—¶
- âœ… AMAã€ç™½åå•ç­‰æ´»åŠ¨å‘å¸ƒåœ°

**æ•°æ®ç‰¹ç‚¹**:
- ç¾¤ç»„/é¢‘é“äºŒåˆ†
- æ”¯æŒæœºå™¨äºº
- æ¶ˆæ¯é‡å·¨å¤§
- éšç§ä¿æŠ¤å¼º

### 2.2 é‡‡é›†ç­–ç•¥

#### ç­–ç•¥ä¸€ï¼šé¢‘é“è®¢é˜…

**ç›®æ ‡**: ç›‘æ§æ‰€æœ‰ä¸»æµåŠ å¯†è´§å¸é¢‘é“

**é¢‘é“åˆ†ç±»**:
```python
CHANNELS = {
    "news": [
        "@coindesk",
        "@cointelegraph",
        "@theblockofficial",
        "@cryptonewsflash",
    ],
    
    "announcements": [
        "@binance_announcements",
        "@coinbase_official",
        "@uniswap_announcements",
        "@ethereum_announcements",
    ],
    
    "alpha": [
        "@cryptogemhunters",
        "@defiprojects",
        "@nftdrops_official",
        "@airdropalerts",
    ],
    
    "kol": [
        "@VitalikChannel",
        "@CZofficialEN",
        "@AltcoinGordon",
    ],
    
    "vc": [
        "@a16zcrypto",
        "@paradigmxyz",
        "@binancelabs",
    ]
}
```

#### ç­–ç•¥äºŒï¼šç¾¤ç»„ç›‘æ§

**ç›®æ ‡**: åŠ å…¥å¹¶ç›‘æ§æ´»è·ƒçš„åŠ å¯†è´§å¸ç¾¤ç»„

**ç¾¤ç»„å‘ç°**:
```python
def discover_crypto_groups():
    """å‘ç°æ–°çš„åŠ å¯†è´§å¸ç¾¤ç»„"""
    
    # æ–¹æ³•1: ä»ç°æœ‰ç¾¤ç»„çš„è®¨è®ºä¸­æå–
    for group in monitored_groups:
        messages = get_recent_messages(group, limit=100)
        
        for msg in messages:
            # æå– t.me/ é“¾æ¥
            invite_links = re.findall(r't\.me/([a-zA-Z0-9_]+)', msg.text)
            
            for link in invite_links:
                if is_crypto_related(link):
                    add_to_monitor_list(link)
    
    # æ–¹æ³•2: ä»Twitteræ¨æ–‡ä¸­æå–
    tweets = search_tweets("telegram.me OR t.me crypto OR web3")
    for tweet in tweets:
        extract_telegram_links(tweet)
    
    # æ–¹æ³•3: çˆ¬å–Telegramç¾¤ç»„ç›®å½•ç½‘ç«™
    directories = [
        "https://telegramchannels.me/crypto",
        "https://tlgrm.eu/channels/crypto",
    ]
```

**ç¾¤ç»„è´¨é‡è¯„ä¼°**:
```python
def assess_group_quality(group_username: str) -> int:
    """è¯„ä¼°ç¾¤ç»„è´¨é‡ï¼ˆ0-100åˆ†ï¼‰"""
    
    info = get_group_info(group_username)
    messages = get_recent_messages(group_username, limit=100)
    
    score = 0
    
    # æˆå‘˜æ•°ï¼ˆ30åˆ†ï¼‰
    members = info["member_count"]
    score += min(30, members / 1000)
    
    # æ´»è·ƒåº¦ï¼ˆ30åˆ†ï¼‰
    daily_messages = len([m for m in messages if is_within_24h(m)])
    score += min(30, daily_messages / 10)
    
    # å†…å®¹è´¨é‡ï¼ˆ20åˆ†ï¼‰
    spam_ratio = count_spam(messages) / len(messages)
    score += max(0, 20 * (1 - spam_ratio))
    
    # å®˜æ–¹è®¤è¯ï¼ˆ20åˆ†ï¼‰
    if info.get("verified"):
        score += 20
    
    return int(score)
```

#### ç­–ç•¥ä¸‰ï¼šå…³é”®ä¿¡æ¯æ•è·

**ç›®æ ‡**: ä»æµ·é‡æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯

**ä¿¡æ¯ç±»å‹**:
```python
class KeyInformation:
    """å…³é”®ä¿¡æ¯ç±»å‹"""
    
    PROJECT_ANNOUNCEMENT = "é¡¹ç›®å…¬å‘Š"        # æ–°é¡¹ç›®å‘å¸ƒ
    FUNDING_NEWS = "èèµ„æ¶ˆæ¯"                # å®Œæˆèèµ„
    TOKEN_LAUNCH = "ä»£å¸ä¸Šçº¿"                # TGE/IDO
    AIRDROP_ALERT = "ç©ºæŠ•é€šçŸ¥"               # ç©ºæŠ•æ´»åŠ¨
    WHITELIST_OPEN = "ç™½åå•å¼€æ”¾"            # ç™½åå•
    TESTNET_LAUNCH = "æµ‹è¯•ç½‘ä¸Šçº¿"            # æµ‹è¯•ç½‘
    MAINNET_LAUNCH = "ä¸»ç½‘ä¸Šçº¿"              # ä¸»ç½‘
    PARTNERSHIP = "åˆä½œä¼™ä¼´"                 # åˆä½œå…¬å‘Š
    AMA_SCHEDULE = "AMAå®‰æ’"                 # AMAæ´»åŠ¨
    CONTRACT_ADDRESS = "åˆçº¦åœ°å€"            # åˆçº¦å‘å¸ƒ


def extract_key_information(message: dict) -> Optional[dict]:
    """æå–å…³é”®ä¿¡æ¯"""
    
    text = message["text"].lower()
    
    # æ£€æµ‹ä¿¡æ¯ç±»å‹
    info_type = None
    
    if any(kw in text for kw in ["announcing", "introduce", "launch"]):
        info_type = KeyInformation.PROJECT_ANNOUNCEMENT
    
    elif any(kw in text for kw in ["raised", "funding", "investment", "seed", "series"]):
        info_type = KeyInformation.FUNDING_NEWS
        # æå–é‡‘é¢
        amount = extract_funding_amount(text)
    
    elif any(kw in text for kw in ["airdrop", "free tokens", "claim"]):
        info_type = KeyInformation.AIRDROP_ALERT
    
    elif any(kw in text for kw in ["whitelist", "early access", "allowlist"]):
        info_type = KeyInformation.WHITELIST_OPEN
    
    elif re.search(r"0x[a-fA-F0-9]{40}", text):
        info_type = KeyInformation.CONTRACT_ADDRESS
        contract = extract_contract_address(text)
    
    # å¦‚æœè¯†åˆ«åˆ°å…³é”®ä¿¡æ¯
    if info_type:
        return {
            "type": info_type,
            "channel": message["channel"],
            "text": message["text"],
            "timestamp": message["date"],
            "importance": calculate_importance(info_type, message)
        }
    
    return None
```

#### ç­–ç•¥å››ï¼šå®˜æ–¹ç¾¤éªŒè¯

**ç›®æ ‡**: åŒºåˆ†å®˜æ–¹ç¾¤å’Œå±±å¯¨ç¾¤

```python
def verify_official_group(group_username: str, project_name: str) -> bool:
    """éªŒè¯æ˜¯å¦ä¸ºå®˜æ–¹ç¾¤"""
    
    # éªŒè¯1: æ£€æŸ¥é¡¹ç›®å®˜ç½‘
    official_links = get_official_links_from_website(project_name)
    if f"t.me/{group_username}" in official_links:
        return True
    
    # éªŒè¯2: æ£€æŸ¥Twitterè®¤è¯
    twitter_bio = get_twitter_bio(project_name)
    if group_username in twitter_bio:
        return True
    
    # éªŒè¯3: æ£€æŸ¥ç¾¤ç»„æè¿°å’Œç®¡ç†å‘˜
    group_info = get_group_info(group_username)
    
    # å®˜æ–¹ç¾¤ç‰¹å¾
    has_project_name = project_name.lower() in group_info["description"].lower()
    has_official_admin = any(
        admin["username"] in KNOWN_TEAM_MEMBERS[project_name]
        for admin in group_info["admins"]
    )
    
    if has_project_name and has_official_admin:
        return True
    
    # éªŒè¯4: äº¤å‰éªŒè¯
    # çœŸæ­£çš„å®˜æ–¹ç¾¤é€šå¸¸ä¼šåœ¨å¤šä¸ªåœ°æ–¹è¢«æåŠ
    mentions = count_official_mentions(group_username, project_name)
    if mentions > 3:
        return True
    
    return False
```

### 2.3 æ•°æ®ç»“æ„è®¾è®¡

```python
class TelegramData(BaseModel):
    """Telegramé‡‡é›†æ•°æ®æ¨¡å‹"""
    
    # åŸºç¡€ä¿¡æ¯
    message_id: int
    chat_id: int
    chat_username: Optional[str]
    chat_title: str
    chat_type: str  # channel, group, supergroup
    
    # å‘é€è€…ä¿¡æ¯
    sender_id: Optional[int]
    sender_username: Optional[str]
    sender_first_name: Optional[str]
    is_bot: bool
    
    # æ¶ˆæ¯å†…å®¹
    text: str
    date: datetime
    edit_date: Optional[datetime]
    
    # äº’åŠ¨æ•°æ®
    views: Optional[int]  # ä»…é¢‘é“æœ‰
    forwards: Optional[int]
    replies: Optional[int]
    
    # åª’ä½“
    has_media: bool
    media_type: Optional[str]  # photo, video, document, audio
    
    # å®ä½“æå–
    urls: List[str]
    mentions: List[str]
    hashtags: List[str]
    cashtags: List[str]
    
    # ç‰¹æ®Šå†…å®¹
    contracts: List[str]  # 0x...
    telegram_links: List[str]  # t.me/...
    
    # åˆ†æç»“æœ
    key_information_type: Optional[str]
    mentioned_projects: List[str]
    importance_score: int  # 0-100
    
    # éªŒè¯ä¿¡æ¯
    is_official_channel: bool
    channel_quality_score: int  # 0-100
    
    # é‡‡é›†å…ƒä¿¡æ¯
    collected_at: datetime
    collection_method: str


class TelegramChannelInfo(BaseModel):
    """Telegramé¢‘é“/ç¾¤ç»„ä¿¡æ¯"""
    
    username: str
    title: str
    description: str
    
    member_count: int
    online_count: Optional[int]
    
    is_verified: bool
    is_scam: bool
    is_fake: bool
    
    created_date: Optional[datetime]
    
    # å…³è”é¡¹ç›®
    related_project: Optional[str]
    is_official: bool
    
    # è´¨é‡è¯„åˆ†
    quality_score: int
    activity_level: str  # high, medium, low
    
    # ç»Ÿè®¡æ•°æ®
    daily_message_count: int
    spam_ratio: float
    
    last_checked: datetime
```

### 2.4 æŠ€æœ¯å®ç°

```python
from telethon import TelegramClient, events
from telethon.tl.types import Channel, MessageMediaDocument

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = TelegramClient(
    'web3_alpha_hunter',
    api_id=TELEGRAM_API_ID,
    api_hash=TELEGRAM_API_HASH
)

# å¯åŠ¨å®¢æˆ·ç«¯
await client.start()


# æ–¹æ³•1: è·å–å†å²æ¶ˆæ¯
async def collect_channel_history(channel_username: str, limit: int = 100):
    """é‡‡é›†é¢‘é“å†å²æ¶ˆæ¯"""
    
    entity = await client.get_entity(channel_username)
    
    messages = []
    async for message in client.iter_messages(entity, limit=limit):
        if message.text:
            messages.append({
                "message_id": message.id,
                "text": message.text,
                "date": message.date,
                "views": message.views,
                "forwards": message.forwards,
            })
    
    return messages


# æ–¹æ³•2: å®æ—¶ç›‘å¬ï¼ˆæ¨èï¼‰
@client.on(events.NewMessage(chats=MONITORED_CHANNELS))
async def handle_new_message(event):
    """å¤„ç†æ–°æ¶ˆæ¯"""
    
    message = event.message
    
    # æå–å…³é”®ä¿¡æ¯
    key_info = extract_key_information({
        "text": message.text,
        "date": message.date,
        "channel": event.chat.username
    })
    
    # å¦‚æœæ˜¯é‡è¦ä¿¡æ¯ï¼Œç«‹å³å¤„ç†
    if key_info and key_info["importance"] > 80:
        await send_urgent_alert(key_info)
        await save_to_database(key_info)
    
    # è®°å½•æ‰€æœ‰æ¶ˆæ¯
    await save_message_to_database(message)


# æ–¹æ³•3: æ‰¹é‡ç›‘æ§
async def monitor_all_channels():
    """ç›‘æ§æ‰€æœ‰é¢‘é“"""
    
    # å¯åŠ¨å®æ—¶ç›‘å¬
    await client.start()
    
    logger.info(f"å¼€å§‹ç›‘æ§ {len(MONITORED_CHANNELS)} ä¸ªé¢‘é“")
    
    # ä¿æŒè¿è¡Œ
    await client.run_until_disconnected()


# é¢‘é“å‘ç°ä¸åŠ å…¥
async def join_channel(channel_username: str):
    """åŠ å…¥é¢‘é“/ç¾¤ç»„"""
    
    try:
        await client(JoinChannelRequest(channel_username))
        logger.info(f"âœ… å·²åŠ å…¥ {channel_username}")
        return True
    except Exception as e:
        logger.error(f"âŒ åŠ å…¥ {channel_username} å¤±è´¥: {e}")
        return False
```

### 2.5 åå°ç¦ç­–ç•¥

```python
# ç­–ç•¥1: å¤šè´¦å·è½®æ¢
telegram_accounts = [
    {"phone": "+1234567890", "api_id": ID1, "api_hash": HASH1},
    {"phone": "+0987654321", "api_id": ID2, "api_hash": HASH2},
]

# ç­–ç•¥2: è¡Œä¸ºæ¨¡æ‹Ÿ
async def human_like_behavior():
    """æ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
    
    # éšæœºå»¶è¿Ÿ
    await asyncio.sleep(random.uniform(5, 15))
    
    # ä¸è¦ä¸€æ¬¡æ€§åŠ å…¥å¤ªå¤šç¾¤ç»„
    max_joins_per_day = 10
    
    # å®šæœŸäº’åŠ¨ï¼ˆç‚¹èµã€å›å¤ï¼‰
    await random_interaction()


# ç­–ç•¥3: é¿å…è§¦å‘ååƒåœ¾æœºåˆ¶
RATE_LIMITS = {
    "join_channel": "10æ¬¡/å¤©",
    "send_message": "20æ¬¡/åˆ†é’Ÿ",
    "forward_message": "30æ¬¡/åˆ†é’Ÿ",
}
```

### 2.6 éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**:
- âœ… èƒ½å¤Ÿç›‘æ§ 100+ é¢‘é“/ç¾¤ç»„
- âœ… èƒ½å¤Ÿå®æ—¶æ¥æ”¶æ–°æ¶ˆæ¯ï¼ˆå»¶è¿Ÿ<30ç§’ï¼‰
- âœ… èƒ½å¤Ÿè‡ªåŠ¨åŠ å…¥æ–°å‘ç°çš„ç¾¤ç»„
- âœ… èƒ½å¤Ÿè¯†åˆ«å®˜æ–¹ç¾¤ vs å±±å¯¨ç¾¤

**æ€§èƒ½éªŒæ”¶**:
- âœ… æ—¥é‡‡é›†é‡ > 3,000æ¡æ¶ˆæ¯
- âœ… å®˜æ–¹å…¬å‘Šæ•è·ç‡ > 95%
- âœ… åˆçº¦åœ°å€è¯†åˆ«å‡†ç¡®ç‡ > 98%

**è´¨é‡éªŒæ”¶**:
- âœ… åƒåœ¾æ¶ˆæ¯è¿‡æ»¤ç‡ > 85%
- âœ… å…³é”®ä¿¡æ¯æå–å‡†ç¡®ç‡ > 90%
- âœ… å®˜æ–¹ç¾¤éªŒè¯å‡†ç¡®ç‡ > 95%

---

## ğŸ® å¹³å°ä¸‰: Discord

### 3.1 å¹³å°ç‰¹ç‚¹

**ä¸ºä»€ä¹ˆé‡è¦**:
- âœ… Web3é¡¹ç›®çš„"æ€»éƒ¨"ï¼ˆå¼€å‘è€…ã€æ ¸å¿ƒç¤¾åŒºèšé›†åœ°ï¼‰
- âœ… æ·±åº¦è®¨è®ºã€æŠ€æœ¯äº¤æµ
- âœ… å®˜æ–¹AMAã€ç™½åå•åˆ†å‘
- âœ… ç¤¾åŒºæ´»è·ƒåº¦æœ€é«˜

**æ•°æ®ç‰¹ç‚¹**:
- æœåŠ¡å™¨-é¢‘é“ç»“æ„
- å®æ—¶æ€§å¼º
- äº’åŠ¨å¤æ‚ï¼ˆå›å¤ã€è¡¨æƒ…ã€æŠ•ç¥¨ï¼‰
- æƒé™ç®¡ç†ä¸¥æ ¼

### 3.2 é‡‡é›†ç­–ç•¥

#### ç­–ç•¥ä¸€ï¼šæœåŠ¡å™¨å‘ç°ä¸åŠ å…¥

**ç›®æ ‡**: åŠ å…¥æ‰€æœ‰ä¸»æµWeb3é¡¹ç›®çš„DiscordæœåŠ¡å™¨

**æœåŠ¡å™¨åˆ†ç±»**:
```python
DISCORD_SERVERS = {
    "layer1": [
        {"name": "Ethereum", "invite": "ethereum-org"},
        {"name": "Solana", "invite": "solana"},
        {"name": "Avalanche", "invite": "avalanche"},
    ],
    
    "defi": [
        {"name": "Uniswap", "invite": "uniswap"},
        {"name": "Aave", "invite": "aave"},
        {"name": "Curve", "invite": "curve"},
    ],
    
    "nft": [
        {"name": "OpenSea", "invite": "opensea"},
        {"name": "Blur", "invite": "blur"},
    ],
    
    "emerging": [
        # æ–°å…´é¡¹ç›®æœåŠ¡å™¨ï¼ˆåŠ¨æ€æ›´æ–°ï¼‰
    ]
}
```

**æœåŠ¡å™¨å‘ç°**:
```python
def discover_discord_servers():
    """å‘ç°æ–°çš„DiscordæœåŠ¡å™¨"""
    
    # æ–¹æ³•1: ä»Twitter/Telegramæå–
    invite_links = []
    
    tweets = search_tweets("discord.gg OR discord.com/invite")
    for tweet in tweets:
        links = re.findall(r'discord\.gg/([a-zA-Z0-9-]+)', tweet.text)
        invite_links.extend(links)
    
    # æ–¹æ³•2: ä»é¡¹ç›®å®˜ç½‘æå–
    for project in discovered_projects:
        website_content = fetch_website(project.website)
        discord_link = extract_discord_link(website_content)
        if discord_link:
            invite_links.append(discord_link)
    
    # æ–¹æ³•3: ä»DiscordæœåŠ¡å™¨åˆ—è¡¨ç½‘ç«™çˆ¬å–
    directories = [
        "https://disboard.org/servers/tag/crypto",
        "https://top.gg/servers/tag/crypto",
    ]
    
    return deduplicate(invite_links)
```

#### ç­–ç•¥äºŒï¼šå…³é”®é¢‘é“ç›‘æ§

**ç›®æ ‡**: ç›‘æ§æœ€é‡è¦çš„é¢‘é“ï¼ˆå…¬å‘Šã€è®¨è®ºã€alphaï¼‰

**é¢‘é“ä¼˜å…ˆçº§**:
```python
CHANNEL_PRIORITY = {
    "announcements": 100,      # å®˜æ–¹å…¬å‘Š - æœ€é«˜ä¼˜å…ˆçº§
    "general": 80,             # ç»¼åˆè®¨è®º
    "alpha": 90,               # alphaé¢‘é“
    "airdrop": 85,             # ç©ºæŠ•ä¿¡æ¯
    "whitelist": 85,           # ç™½åå•
    "partnerships": 75,        # åˆä½œå…¬å‘Š
    "development": 70,         # å¼€å‘è¿›å±•
    "trading": 60,             # äº¤æ˜“è®¨è®º
    "memes": 20,               # è¡¨æƒ…åŒ…ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
}

def monitor_key_channels(guild_id: int):
    """ç›‘æ§å…³é”®é¢‘é“"""
    
    guild = client.get_guild(guild_id)
    
    for channel in guild.text_channels:
        # è®¡ç®—é¢‘é“é‡è¦æ€§
        importance = calculate_channel_importance(channel)
        
        if importance > 60:
            # æ·»åŠ åˆ°ç›‘æ§åˆ—è¡¨
            add_to_monitor(channel)


def calculate_channel_importance(channel) -> int:
    """è®¡ç®—é¢‘é“é‡è¦æ€§"""
    
    score = 0
    
    # åŸºäºé¢‘é“åç§°
    for keyword, priority in CHANNEL_PRIORITY.items():
        if keyword in channel.name.lower():
            score = max(score, priority)
    
    # åŸºäºæ¶ˆæ¯é¢‘ç‡
    recent_messages = get_recent_message_count(channel, hours=24)
    score += min(20, recent_messages / 50)
    
    # åŸºäºæˆå‘˜äº’åŠ¨
    # ...
    
    return int(score)
```

#### ç­–ç•¥ä¸‰ï¼šå®æ—¶æ¶ˆæ¯æ•è·

**ç›®æ ‡**: æ•è·æ‰€æœ‰å…³é”®æ¶ˆæ¯ï¼Œç‰¹åˆ«æ˜¯å…¬å‘Šå’Œalphaä¿¡æ¯

```python
import discord
from discord.ext import commands

# åˆ›å»ºBot
intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True
intents.members = True

bot = commands.Bot(command_prefix='!', intents=intents)


@bot.event
async def on_ready():
    """Botå°±ç»ª"""
    logger.info(f'âœ… Discord Bot logged in as {bot.user}')
    logger.info(f'ç›‘æ§ {len(bot.guilds)} ä¸ªæœåŠ¡å™¨')


@bot.event
async def on_message(message):
    """å¤„ç†æ–°æ¶ˆæ¯"""
    
    # å¿½ç•¥botè‡ªå·±çš„æ¶ˆæ¯
    if message.author.bot:
        return
    
    # åªå¤„ç†å…³é”®é¢‘é“
    if not is_key_channel(message.channel):
        return
    
    # æå–å…³é”®ä¿¡æ¯
    key_info = extract_key_information({
        "text": message.content,
        "channel": message.channel.name,
        "guild": message.guild.name,
        "author": message.author.name,
        "timestamp": message.created_at
    })
    
    # å¦‚æœæ˜¯é‡è¦æ¶ˆæ¯
    if key_info and key_info["importance"] > 80:
        # ç«‹å³æ¨é€
        await send_alert(key_info)
    
    # ä¿å­˜æ‰€æœ‰æ¶ˆæ¯
    await save_to_database({
        "message_id": message.id,
        "channel_id": message.channel.id,
        "guild_id": message.guild.id,
        "author_id": message.author.id,
        "content": message.content,
        "created_at": message.created_at,
        "attachments": [att.url for att in message.attachments],
        "embeds": len(message.embeds),
    })


@bot.event
async def on_guild_join(guild):
    """åŠ å…¥æ–°æœåŠ¡å™¨"""
    logger.info(f'âœ… åŠ å…¥æœåŠ¡å™¨: {guild.name}')
    
    # åˆ†ææœåŠ¡å™¨
    analysis = analyze_guild(guild)
    save_guild_info(analysis)
    
    # è¯†åˆ«å…³é”®é¢‘é“
    key_channels = identify_key_channels(guild)
    for channel in key_channels:
        logger.info(f'  - å…³é”®é¢‘é“: #{channel.name}')
```

#### ç­–ç•¥å››ï¼šç¤¾åŒºæ´»è·ƒåº¦åˆ†æ

**ç›®æ ‡**: è¯„ä¼°é¡¹ç›®ç¤¾åŒºçš„çœŸå®æ´»è·ƒåº¦

```python
async def analyze_community_activity(guild_id: int) -> dict:
    """åˆ†æç¤¾åŒºæ´»è·ƒåº¦"""
    
    guild = bot.get_guild(guild_id)
    
    # 1. æˆå‘˜ç»Ÿè®¡
    total_members = guild.member_count
    online_members = len([m for m in guild.members if m.status != discord.Status.offline])
    
    # 2. æ¶ˆæ¯ç»Ÿè®¡ï¼ˆè¿‡å»24å°æ—¶ï¼‰
    message_count = 0
    unique_authors = set()
    
    for channel in guild.text_channels:
        try:
            async for message in channel.history(limit=100, after=datetime.now() - timedelta(hours=24)):
                message_count += 1
                unique_authors.add(message.author.id)
        except:
            pass  # æ— æƒé™è®¿é—®çš„é¢‘é“
    
    # 3. äº’åŠ¨è´¨é‡
    avg_message_length = calculate_avg_message_length(guild)
    bot_ratio = count_bot_messages(guild) / message_count if message_count > 0 else 0
    
    # 4. è®¡ç®—æ´»è·ƒåº¦åˆ†æ•°
    activity_score = (
        min(30, total_members / 1000) +              # æˆå‘˜æ•°ï¼ˆ30åˆ†ï¼‰
        min(30, message_count / 100) +               # æ¶ˆæ¯é‡ï¼ˆ30åˆ†ï¼‰
        min(20, len(unique_authors) / 50) +          # æ´»è·ƒç”¨æˆ·ï¼ˆ20åˆ†ï¼‰
        min(20, (1 - bot_ratio) * 20)                # çœŸäººæ¯”ä¾‹ï¼ˆ20åˆ†ï¼‰
    )
    
    return {
        "guild_id": guild_id,
        "guild_name": guild.name,
        "total_members": total_members,
        "online_members": online_members,
        "daily_messages": message_count,
        "active_users": len(unique_authors),
        "bot_ratio": f"{bot_ratio*100:.1f}%",
        "activity_score": int(activity_score),
        "activity_level": "High" if activity_score > 70 else "Medium" if activity_score > 40 else "Low"
    }
```

### 3.3 æ•°æ®ç»“æ„è®¾è®¡

```python
class DiscordData(BaseModel):
    """Discordé‡‡é›†æ•°æ®æ¨¡å‹"""
    
    # åŸºç¡€ä¿¡æ¯
    message_id: int
    channel_id: int
    channel_name: str
    guild_id: int
    guild_name: str
    
    # ä½œè€…ä¿¡æ¯
    author_id: int
    author_name: str
    author_discriminator: str
    author_is_bot: bool
    author_roles: List[str]
    
    # æ¶ˆæ¯å†…å®¹
    content: str
    created_at: datetime
    edited_at: Optional[datetime]
    
    # äº’åŠ¨æ•°æ®
    reactions: List[Dict[str, int]]  # [{emoji: count}]
    reply_count: int
    
    # é™„ä»¶
    attachments: List[str]  # URLs
    embeds: List[dict]
    
    # å¼•ç”¨
    referenced_message_id: Optional[int]
    is_thread_starter: bool
    
    # å®ä½“æå–
    mentions: List[str]
    role_mentions: List[str]
    urls: List[str]
    
    # åˆ†æç»“æœ
    key_information_type: Optional[str]
    importance_score: int
    
    # é‡‡é›†å…ƒä¿¡æ¯
    collected_at: datetime


class DiscordGuildInfo(BaseModel):
    """DiscordæœåŠ¡å™¨ä¿¡æ¯"""
    
    guild_id: int
    name: str
    description: Optional[str]
    
    # è§„æ¨¡
    member_count: int
    online_count: int
    
    # éªŒè¯
    is_verified: bool
    is_partnered: bool
    
    # å…³è”é¡¹ç›®
    related_project: Optional[str]
    is_official: bool
    
    # æ´»è·ƒåº¦
    activity_score: int
    daily_message_count: int
    active_user_count: int
    
    # é¢‘é“ç»Ÿè®¡
    text_channel_count: int
    key_channels: List[str]
    
    created_at: datetime
    joined_at: datetime
    last_checked: datetime
```

### 3.4 éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**:
- âœ… èƒ½å¤ŸåŠ å…¥ 50+ DiscordæœåŠ¡å™¨
- âœ… èƒ½å¤Ÿå®æ—¶ç›‘æ§å…³é”®é¢‘é“
- âœ… èƒ½å¤Ÿè¯†åˆ«å…¬å‘Šå’Œé‡è¦æ¶ˆæ¯
- âœ… èƒ½å¤Ÿåˆ†æç¤¾åŒºæ´»è·ƒåº¦

**æ€§èƒ½éªŒæ”¶**:
- âœ… æ—¥é‡‡é›†é‡ > 2,000æ¡æ¶ˆæ¯
- âœ… æ¶ˆæ¯å»¶è¿Ÿ < 5ç§’
- âœ… å®˜æ–¹å…¬å‘Šæ•è·ç‡ > 95%

**è´¨é‡éªŒæ”¶**:
- âœ… åƒåœ¾æ¶ˆæ¯è¿‡æ»¤ç‡ > 80%
- âœ… ç¤¾åŒºæ´»è·ƒåº¦è¯„ä¼°å‡†ç¡®ç‡ > 85%

---

## ğŸ“ å¹³å°å››: Medium

### 4.1 å¹³å°ç‰¹ç‚¹

**ä¸ºä»€ä¹ˆé‡è¦**:
- âœ… é¡¹ç›®æ·±åº¦æ–‡ç« å‘å¸ƒåœ°
- âœ… æŠ€æœ¯è§£æã€è·¯çº¿å›¾ã€æ›´æ–°æ—¥å¿—
- âœ… æŠ•èµ„äººåˆ†ææ–‡ç« 
- âœ… é¡¹ç›®æ–¹å®˜æ–¹åšå®¢

**æ•°æ®ç‰¹ç‚¹**:
- é•¿æ–‡æœ¬ï¼ˆ1000-5000å­—ï¼‰
- ç»“æ„åŒ–å†…å®¹
- SEOå‹å¥½
- è®¢é˜…åˆ¶

### 4.2 é‡‡é›†ç­–ç•¥

#### ç­–ç•¥ä¸€ï¼šRSSè®¢é˜…

**ç›®æ ‡**: è®¢é˜…æ‰€æœ‰Web3ç›¸å…³çš„Mediumå‡ºç‰ˆç‰©å’Œä½œè€…

```python
import feedparser

MEDIUM_RSS_SOURCES = [
    # é¡¶çº§å‡ºç‰ˆç‰©
    "https://medium.com/feed/@VitalikButerin",
    "https://medium.com/feed/@a16z",
    "https://medium.com/feed/ethereum-optimism",
    "https://medium.com/feed/coinmonks",
    "https://medium.com/feed/coinbase",
    
    # æ ‡ç­¾è®¢é˜…
    "https://medium.com/feed/tag/web3",
    "https://medium.com/feed/tag/defi",
    "https://medium.com/feed/tag/cryptocurrency",
]

def collect_medium_articles():
    """é‡‡é›†Mediumæ–‡ç« """
    
    articles = []
    
    for rss_url in MEDIUM_RSS_SOURCES:
        feed = feedparser.parse(rss_url)
        
        for entry in feed.entries:
            article = {
                "title": entry.title,
                "url": entry.link,
                "author": entry.author,
                "published": entry.published_parsed,
                "summary": entry.summary,
                "tags": entry.get("tags", []),
            }
            
            # åªé‡‡é›†Web3ç›¸å…³
            if is_web3_related(article):
                articles.append(article)
    
    return articles
```

#### ç­–ç•¥äºŒï¼šå…³é”®è¯æœç´¢

**ç›®æ ‡**: ä¸»åŠ¨æœç´¢ç‰¹å®šå…³é”®è¯çš„æ–‡ç« 

```python
def search_medium(keyword: str, max_results: int = 50):
    """æœç´¢Mediumæ–‡ç« """
    
    # Mediumæ²¡æœ‰å®˜æ–¹APIï¼Œä½¿ç”¨Googleæœç´¢
    query = f"site:medium.com {keyword}"
    
    results = google_search(query, num_results=max_results)
    
    articles = []
    for result in results:
        article = scrape_medium_article(result["url"])
        articles.append(article)
    
    return articles
```

#### ç­–ç•¥ä¸‰ï¼šå…¨æ–‡æå–ä¸åˆ†æ

**ç›®æ ‡**: æå–æ–‡ç« å…¨æ–‡å¹¶è¿›è¡Œæ·±åº¦åˆ†æ

```python
from bs4 import BeautifulSoup
import requests

def scrape_medium_article(url: str) -> dict:
    """çˆ¬å–Mediumæ–‡ç« """
    
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # æå–æ ‡é¢˜
    title = soup.find('h1').text
    
    # æå–ä½œè€…
    author = soup.find('a', {'data-action': 'show-user-card'}).text
    
    # æå–å‘å¸ƒæ—¶é—´
    published = soup.find('time')['datetime']
    
    # æå–æ­£æ–‡ï¼ˆMediumçš„æ–‡ç« å†…å®¹åœ¨articleæ ‡ç­¾ä¸­ï¼‰
    article_body = soup.find('article')
    paragraphs = article_body.find_all('p')
    full_text = '\n\n'.join([p.text for p in paragraphs])
    
    # æå–ç»Ÿè®¡æ•°æ®
    claps = extract_claps(soup)
    responses = extract_responses(soup)
    
    # æå–æåŠçš„é¡¹ç›®
    mentioned_projects = extract_project_mentions(full_text)
    
    return {
        "url": url,
        "title": title,
        "author": author,
        "published": published,
        "full_text": full_text,
        "word_count": len(full_text.split()),
        "claps": claps,
        "responses": responses,
        "mentioned_projects": mentioned_projects,
    }


def analyze_medium_article(article: dict) -> dict:
    """åˆ†æMediumæ–‡ç« """
    
    # AIæå–å…³é”®ä¿¡æ¯
    analysis = ai_analyze_article(article["full_text"])
    
    return {
        "article_url": article["url"],
        
        # ä¸»é¢˜åˆ†ç±»
        "topic": analysis["topic"],  # Technical, Investment, Update, Tutorial
        
        # æåŠçš„é¡¹ç›®
        "projects": analysis["projects"],
        
        # å…³é”®æ´å¯Ÿ
        "key_insights": analysis["insights"],
        
        # æƒ…æ„Ÿå€¾å‘
        "sentiment": analysis["sentiment"],  # Bullish, Neutral, Bearish
        
        # é‡è¦æ€§è¯„åˆ†
        "importance": analysis["importance"],  # 0-100
        
        # æ˜¯å¦åŒ…å«Alphaä¿¡æ¯
        "has_alpha": analysis["has_alpha"],
    }
```

### 4.3 æ•°æ®ç»“æ„è®¾è®¡

```python
class MediumArticle(BaseModel):
    """Mediumæ–‡ç« æ•°æ®æ¨¡å‹"""
    
    # åŸºç¡€ä¿¡æ¯
    url: str
    title: str
    subtitle: Optional[str]
    
    # ä½œè€…ä¿¡æ¯
    author: str
    author_url: str
    author_followers: Optional[int]
    
    # å‘å¸ƒä¿¡æ¯
    published_at: datetime
    updated_at: Optional[datetime]
    publication: Optional[str]  # æ‰€å±å‡ºç‰ˆç‰©
    
    # å†…å®¹
    full_text: str
    word_count: int
    reading_time_minutes: int
    
    # äº’åŠ¨æ•°æ®
    claps: int
    responses: int
    
    # åˆ†ç±»
    tags: List[str]
    topics: List[str]
    
    # æåŠçš„é¡¹ç›®
    mentioned_projects: List[str]
    
    # AIåˆ†æç»“æœ
    article_type: str  # Technical, Investment, Update, Tutorial
    key_insights: List[str]
    sentiment: str
    importance_score: int
    has_alpha: bool
    
    # é‡‡é›†å…ƒä¿¡æ¯
    collected_at: datetime
    source: str  # rss, search, manual
```

### 4.4 éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**:
- âœ… èƒ½å¤Ÿè®¢é˜… 50+ RSSæº
- âœ… èƒ½å¤Ÿæœç´¢ç‰¹å®šå…³é”®è¯æ–‡ç« 
- âœ… èƒ½å¤Ÿæå–æ–‡ç« å…¨æ–‡
- âœ… èƒ½å¤Ÿè¯†åˆ«æåŠçš„é¡¹ç›®

**æ€§èƒ½éªŒæ”¶**:
- âœ… æ—¥é‡‡é›†é‡ > 200ç¯‡æ–‡ç« 
- âœ… å…¨æ–‡æå–å‡†ç¡®ç‡ > 95%

**è´¨é‡éªŒæ”¶**:
- âœ… é¡¹ç›®æåŠè¯†åˆ«å‡†ç¡®ç‡ > 85%
- âœ… æ–‡ç« åˆ†ç±»å‡†ç¡®ç‡ > 80%

---

## ğŸ“Š æ•°æ®é‡‡é›†æ€»æ§ç³»ç»Ÿ

### ç»Ÿä¸€è°ƒåº¦å™¨

```python
from celery import Celery
from celery.schedules import crontab

app = Celery('multi_platform_collector')

# Twitteré‡‡é›†ä»»åŠ¡
@app.task
def collect_twitter():
    collector = TwitterCollector()
    data = collector.collect_and_extract(hours=1)
    process_and_save(data, platform="twitter")

# Telegramé‡‡é›†ä»»åŠ¡
@app.task
def collect_telegram():
    collector = TelegramCollector()
    data = await collector.collect_and_extract(hours=1)
    process_and_save(data, platform="telegram")

# Discordé‡‡é›†ä»»åŠ¡
@app.task
def collect_discord():
    # Discordé€šè¿‡Botå®æ—¶ç›‘å¬ï¼Œæ— éœ€å®šæ—¶ä»»åŠ¡
    pass

# Mediumé‡‡é›†ä»»åŠ¡
@app.task
def collect_medium():
    collector = MediumCollector()
    data = collector.collect_articles()
    process_and_save(data, platform="medium")


# ä»»åŠ¡è°ƒåº¦é…ç½®
app.conf.beat_schedule = {
    'twitter-every-5min': {
        'task': 'collect_twitter',
        'schedule': 300.0,
    },
    'telegram-every-15min': {
        'task': 'collect_telegram',
        'schedule': 900.0,
    },
    'medium-every-hour': {
        'task': 'collect_medium',
        'schedule': 3600.0,
    },
}
```

### æ•°æ®å½’ä¸€åŒ–

```python
class UnifiedProjectData(BaseModel):
    """ç»Ÿä¸€çš„é¡¹ç›®æ•°æ®æ¨¡å‹"""
    
    # é¡¹ç›®æ ‡è¯†
    project_name: str
    project_id: Optional[str]
    
    # å‘ç°ä¿¡æ¯
    first_discovered_at: datetime
    discovery_source: str  # twitter, telegram, discord, medium
    discovery_context: str
    
    # å¤šå¹³å°æ•°æ®èšåˆ
    twitter_mentions: int
    telegram_mentions: int
    discord_mentions: int
    medium_mentions: int
    
    # ç»¼åˆæŒ‡æ ‡
    total_mentions: int
    mention_growth_rate: float
    cross_platform_consistency: float  # 0-1ï¼Œè·¨å¹³å°ä¸€è‡´æ€§
    
    # ä¿¡å·å¼ºåº¦
    overall_signal_strength: int  # 0-100
    
    # æœ€åæ›´æ–°
    last_updated: datetime


def aggregate_multi_platform_data(project_name: str) -> UnifiedProjectData:
    """èšåˆå¤šå¹³å°æ•°æ®"""
    
    # ä»å„å¹³å°è·å–æ•°æ®
    twitter_data = get_twitter_mentions(project_name)
    telegram_data = get_telegram_mentions(project_name)
    discord_data = get_discord_mentions(project_name)
    medium_data = get_medium_mentions(project_name)
    
    # è®¡ç®—ç»¼åˆæŒ‡æ ‡
    total = len(twitter_data) + len(telegram_data) + len(discord_data) + len(medium_data)
    
    # è®¡ç®—å¢é•¿ç‡
    growth = calculate_mention_growth(project_name, days=7)
    
    # è®¡ç®—è·¨å¹³å°ä¸€è‡´æ€§
    consistency = calculate_cross_platform_consistency(
        twitter_data, telegram_data, discord_data, medium_data
    )
    
    # è®¡ç®—ç»¼åˆä¿¡å·å¼ºåº¦
    signal = calculate_overall_signal(
        twitter_data, telegram_data, discord_data, medium_data
    )
    
    return UnifiedProjectData(
        project_name=project_name,
        first_discovered_at=find_earliest_mention(project_name),
        discovery_source=find_first_source(project_name),
        twitter_mentions=len(twitter_data),
        telegram_mentions=len(telegram_data),
        discord_mentions=len(discord_data),
        medium_mentions=len(medium_data),
        total_mentions=total,
        mention_growth_rate=growth,
        cross_platform_consistency=consistency,
        overall_signal_strength=signal,
        last_updated=datetime.now()
    )
```

---

## ğŸ“‹ å®æ–½è®¡åˆ’

### Week 1-2: ç¬¬ä¸€æ¢¯é˜Ÿå¹³å°
- **Day 1-3**: Twitterå¢å¼ºï¼ˆè¯„è®ºåŒºæŒ–æ˜ã€è¯é¢˜è¿½è¸ªï¼‰
- **Day 4-6**: Telegramå¢å¼ºï¼ˆç¾¤ç»„ç›‘æ§ã€å®˜æ–¹éªŒè¯ï¼‰
- **Day 7-10**: Discordå®ç°ï¼ˆBotå¼€å‘ã€é¢‘é“ç›‘æ§ï¼‰
- **Day 11-14**: Mediumå®ç°ï¼ˆRSSè®¢é˜…ã€å…¨æ–‡æå–ï¼‰

### Week 3-4: æ•°æ®å¤„ç†ä¸åˆ†æ
- **Day 15-18**: æ•°æ®å½’ä¸€åŒ–ä¸å»é‡
- **Day 19-22**: è·¨å¹³å°äº¤å‰éªŒè¯
- **Day 23-26**: çƒ­åº¦è¿½è¸ªç®—æ³•
- **Day 27-28**: æµ‹è¯•ä¸ä¼˜åŒ–

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-04  
**è´Ÿè´£äºº**: äº§å“ç»ç†

