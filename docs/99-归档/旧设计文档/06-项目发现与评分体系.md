# é¡¹ç›®å‘ç°ä¸è¯„åˆ†ä½“ç³»

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**æ–‡æ¡£ç›®æ ‡**: è®¾è®¡ä»è¯é¢˜çƒ­åº¦å’Œè¯„è®ºåŒºå‘ç°æ—©æœŸé¡¹ç›®çš„å®Œæ•´æ–¹æ³•è®º  
**æ ¸å¿ƒç†å¿µ**: æ•°æ®é©±åŠ¨ + äº¤å‰éªŒè¯ + AIè¯„åˆ†  
**æ›´æ–°æ—¶é—´**: 2025-10-04

---

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

**æˆ‘ä»¬è¦å‘ç°ä»€ä¹ˆæ ·çš„é¡¹ç›®ï¼Ÿ**

1. **æœªå‘å¸ä½†æœ‰æ½œåŠ›** - Pre-Tokené¡¹ç›®
2. **è¯é¢˜çƒ­åº¦ä¸Šå‡** - ç¤¾åŒºè®¨è®ºå¢åŠ 
3. **å¤šå¹³å°éªŒè¯** - ä¸æ˜¯å•ä¸€æ¥æºçš„ç‚’ä½œ
4. **å›¢é˜ŸèƒŒæ™¯ä¼˜è´¨** - æœ‰æˆåŠŸç»éªŒæˆ–é¡¶çº§VCèƒŒä¹¦
5. **æŠ€æœ¯æœ‰åˆ›æ–°** - ä¸æ˜¯ç®€å•Copy

**ç›®æ ‡ROI**: åœ¨é¡¹ç›®å‘å¸åå®ç° 10-100å€æ”¶ç›Š

---

## ğŸ” é¡¹ç›®å‘ç°æµç¨‹

### æ•´ä½“æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬ä¸€æ­¥: å¤šå¹³å°æ•°æ®é‡‡é›†                                         â”‚
â”‚  Twitter + Telegram + Discord + Medium + GitHub                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬äºŒæ­¥: é¡¹ç›®åç§°æå–ä¸èšåˆ                                     â”‚
â”‚  NLPè¯†åˆ« + æ­£åˆ™åŒ¹é… + å®ä½“è¯†åˆ«                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬ä¸‰æ­¥: åˆæ­¥ç­›é€‰ï¼ˆå»é™¤å™ªéŸ³ï¼‰                                   â”‚
â”‚  å·²å‘å¸è¿‡æ»¤ + è¯ˆéª—é¡¹ç›®è¿‡æ»¤ + ä½è´¨é‡è¿‡æ»¤                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬å››æ­¥: äº¤å‰éªŒè¯ï¼ˆå¤šæºç¡®è®¤ï¼‰                                   â”‚
â”‚  è‡³å°‘2ä¸ªå¹³å°æåŠ + å®˜æ–¹æ¸ é“éªŒè¯ + å›¢é˜ŸçœŸå®æ€§éªŒè¯               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬äº”æ­¥: æ·±åº¦æ•°æ®æ”¶é›†                                           â”‚
â”‚  ç¤¾äº¤åª’ä½“æ•°æ® + GitHubæ•°æ® + èèµ„ä¿¡æ¯ + é“¾ä¸Šæ•°æ®               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬å…­æ­¥: AIç»¼åˆè¯„åˆ†                                             â”‚
â”‚  6ç»´åº¦è¯„åˆ†æ¨¡å‹ + å‘å¸æ¦‚ç‡é¢„æµ‹ + ç©ºæŠ•ä»·å€¼ä¼°ç®—                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬ä¸ƒæ­¥: åˆ†çº§ä¸æ¨é€                                             â”‚
â”‚  Sçº§(ç«‹å³æ¨é€) Açº§(æ¯æ—¥æŠ¥å‘Š) Bçº§(è§‚å¯Ÿ) Cçº§(å¿½ç•¥)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ç¬¬ä¸€æ­¥: ä»è¯é¢˜çƒ­åº¦å‘ç°é¡¹ç›®

### 1.1 çƒ­åº¦æŒ‡æ ‡å®šä¹‰

**ä»€ä¹ˆæ˜¯"çƒ­åº¦"ï¼Ÿ**

çƒ­åº¦ = æåŠé¢‘æ¬¡ Ã— å¢é•¿é€Ÿåº¦ Ã— KOLå‚ä¸åº¦ Ã— æƒ…æ„Ÿå€¾å‘

```python
def calculate_topic_heat(project_name: str, time_window: int = 24) -> float:
    """è®¡ç®—é¡¹ç›®è¯é¢˜çƒ­åº¦"""
    
    # 1. æåŠé¢‘æ¬¡ï¼ˆ40%æƒé‡ï¼‰
    mentions = count_mentions(project_name, hours=time_window)
    mention_score = min(40, mentions / 10)  # æ¯10æ¬¡æåŠå¾—1åˆ†ï¼Œæœ€é«˜40åˆ†
    
    # 2. å¢é•¿é€Ÿåº¦ï¼ˆ30%æƒé‡ï¼‰
    previous_mentions = count_mentions(project_name, hours=time_window*2, offset=time_window)
    growth_rate = (mentions - previous_mentions) / previous_mentions if previous_mentions > 0 else 0
    growth_score = min(30, growth_rate * 100)  # å¢é•¿ç‡100%=30åˆ†
    
    # 3. KOLå‚ä¸åº¦ï¼ˆ20%æƒé‡ï¼‰
    kol_mentions = count_kol_mentions(project_name, hours=time_window)
    kol_score = min(20, kol_mentions * 4)  # æ¯ä¸ªKOLæåŠå¾—4åˆ†
    
    # 4. æƒ…æ„Ÿå€¾å‘ï¼ˆ10%æƒé‡ï¼‰
    sentiment = analyze_sentiment(project_name)
    sentiment_score = sentiment * 10  # -1åˆ°1æ˜ å°„åˆ°-10åˆ°10
    
    total_heat = mention_score + growth_score + kol_score + sentiment_score
    
    return max(0, min(100, total_heat))
```

### 1.2 çªç„¶çˆ†å‘æ£€æµ‹

**ç›®æ ‡**: å‘ç°çªç„¶å¼€å§‹è¢«è®¨è®ºçš„é¡¹ç›®

```python
def detect_sudden_surge(project_name: str) -> dict:
    """æ£€æµ‹çªç„¶çˆ†å‘çš„é¡¹ç›®"""
    
    # è·å–è¿‡å»7å¤©çš„æ¯å°æ—¶æåŠæ•°
    hourly_mentions = []
    for hour in range(7 * 24):
        count = count_mentions(project_name, hours=1, offset=hour)
        hourly_mentions.append(count)
    
    # è®¡ç®—åŸºçº¿ï¼ˆå‰6å¤©çš„å¹³å‡å€¼ï¼‰
    baseline = sum(hourly_mentions[:144]) / 144
    
    # è®¡ç®—æœ€è¿‘24å°æ—¶çš„å¹³å‡å€¼
    recent_avg = sum(hourly_mentions[-24:]) / 24
    
    # åˆ¤æ–­æ˜¯å¦çªç„¶çˆ†å‘
    surge_ratio = recent_avg / baseline if baseline > 0 else 0
    
    is_surge = surge_ratio > 3  # å¢é•¿è¶…è¿‡3å€è§†ä¸ºçˆ†å‘
    
    return {
        "project": project_name,
        "baseline_mentions_per_hour": baseline,
        "recent_mentions_per_hour": recent_avg,
        "surge_ratio": surge_ratio,
        "is_sudden_surge": is_surge,
        "surge_start_time": find_surge_start(hourly_mentions) if is_surge else None
    }


def find_surge_start(hourly_data: List[int]) -> datetime:
    """æ‰¾åˆ°çˆ†å‘èµ·å§‹æ—¶é—´"""
    
    baseline = sum(hourly_data[:144]) / 144
    
    # ä»åå¾€å‰æ‰¾ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªè¶…è¿‡åŸºçº¿2å€çš„ç‚¹
    for i in range(len(hourly_data) - 1, 143, -1):
        if hourly_data[i] > baseline * 2:
            continue
        else:
            # æ‰¾åˆ°çˆ†å‘èµ·å§‹ç‚¹
            return datetime.now() - timedelta(hours=len(hourly_data) - i - 1)
    
    return datetime.now()
```

### 1.3 è¯„è®ºåŒºæŒ–æ˜ç®—æ³•

**ç›®æ ‡**: ä»é«˜äº’åŠ¨å¸–å­çš„è¯„è®ºåŒºå‘ç°æ—©æœŸé¡¹ç›®

```python
def mine_comments_for_projects(post_id: str, platform: str) -> List[dict]:
    """ä»è¯„è®ºåŒºæŒ–æ˜é¡¹ç›®"""
    
    # 1. è·å–æ‰€æœ‰è¯„è®º
    comments = get_all_comments(post_id, platform)
    
    # 2. è´¨é‡è¿‡æ»¤ï¼ˆå‚è€ƒ05æ–‡æ¡£ä¸­çš„è´¨é‡è¯„åˆ†ï¼‰
    quality_comments = [c for c in comments if c["quality_score"] > 60]
    
    # 3. æå–é¡¹ç›®æåŠ
    project_mentions = []
    
    for comment in quality_comments:
        # ä½¿ç”¨NLPæå–é¡¹ç›®åç§°
        projects = extract_project_names(comment["text"])
        
        for project in projects:
            # æ£€æŸ¥æ˜¯å¦å·²çŸ¥é¡¹ç›®
            is_known = check_if_known_project(project)
            
            if not is_known:
                # æ–°å‘ç°çš„é¡¹ç›®
                project_mentions.append({
                    "project_name": project,
                    "mentioned_in_comment": comment["id"],
                    "comment_author": comment["author"],
                    "comment_likes": comment["likes"],
                    "context": extract_context(comment["text"], project),
                    "sentiment": analyze_sentiment_towards(comment["text"], project),
                    "platform": platform,
                    "discovered_at": datetime.now()
                })
    
    # 4. èšåˆç›¸åŒé¡¹ç›®çš„æåŠ
    aggregated = aggregate_mentions(project_mentions)
    
    return aggregated


def extract_project_names(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–é¡¹ç›®åç§°"""
    
    projects = []
    
    # æ–¹æ³•1: æ­£åˆ™åŒ¹é…ï¼ˆå¤§å†™å¼€å¤´çš„è¯ç»„ï¼‰
    # ä¾‹å¦‚: "Uniswap", "Ethereum Name Service"
    pattern1 = r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b'
    matches1 = re.findall(pattern1, text)
    projects.extend(matches1)
    
    # æ–¹æ³•2: è¯†åˆ«ç‰¹å®šæ¨¡å¼
    # ä¾‹å¦‚: "Check out XXX Protocol"
    pattern2 = r'check out\s+([A-Z][a-zA-Z\s]+?)(?:\.|,|$)'
    matches2 = re.findall(pattern2, text, re.IGNORECASE)
    projects.extend(matches2)
    
    # æ–¹æ³•3: è¯†åˆ«ç½‘ç«™é“¾æ¥
    # ä¾‹å¦‚: "uniswap.org" -> "Uniswap"
    urls = re.findall(r'https?://([a-zA-Z0-9-]+)\.[a-z]+', text)
    for url in urls:
        project_name = url.replace('-', ' ').title()
        projects.append(project_name)
    
    # æ–¹æ³•4: NERå‘½åå®ä½“è¯†åˆ«ï¼ˆä½¿ç”¨AIï¼‰
    ner_projects = ai_extract_project_names(text)
    projects.extend(ner_projects)
    
    # å»é‡å’Œæ¸…æ´—
    projects = list(set([p.strip() for p in projects]))
    
    # è¿‡æ»¤å™ªéŸ³ï¼ˆé€šç”¨è¯æ±‡ï¼‰
    noise_words = ["Bitcoin", "Ethereum", "Solana"]  # å·²çŸ¥å¤§é¡¹ç›®
    projects = [p for p in projects if p not in noise_words]
    
    return projects


def ai_extract_project_names(text: str) -> List[str]:
    """ä½¿ç”¨AIæå–é¡¹ç›®åç§°"""
    
    prompt = f"""
    ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰æåŠçš„Web3é¡¹ç›®åç§°ã€‚
    åªè¿”å›é¡¹ç›®åç§°ï¼Œæ¯è¡Œä¸€ä¸ªã€‚
    å¦‚æœæ²¡æœ‰æåŠä»»ä½•é¡¹ç›®ï¼Œè¿”å›ç©ºã€‚
    
    æ–‡æœ¬ï¼š
    {text}
    
    é¡¹ç›®åç§°ï¼š
    """
    
    response = call_ai_api(prompt, model="gpt-4")
    
    # è§£æå“åº”
    projects = [line.strip() for line in response.split('\n') if line.strip()]
    
    return projects
```

### 1.4 å¤šç»´åº¦ä¿¡å·èšåˆ

**ç›®æ ‡**: ä»å¤šä¸ªç»´åº¦ç»¼åˆåˆ¤æ–­é¡¹ç›®çƒ­åº¦

```python
class ProjectSignal(BaseModel):
    """é¡¹ç›®ä¿¡å·"""
    
    project_name: str
    
    # æåŠæ•°æ®
    twitter_mentions: int
    telegram_mentions: int
    discord_mentions: int
    medium_mentions: int
    reddit_mentions: int
    
    # å¢é•¿æ•°æ®
    mention_growth_24h: float  # 24å°æ—¶å¢é•¿ç‡
    mention_growth_7d: float   # 7å¤©å¢é•¿ç‡
    
    # KOLæ•°æ®
    kol_tier1_mentions: int
    kol_tier2_mentions: int
    kol_tier3_mentions: int
    
    # è¯„è®ºåŒºæ•°æ®
    comment_discovery_count: int  # è¯„è®ºåŒºå‘ç°æ¬¡æ•°
    avg_comment_quality: float    # å¹³å‡è¯„è®ºè´¨é‡
    
    # æƒ…æ„Ÿæ•°æ®
    positive_ratio: float  # æ­£é¢æƒ…æ„Ÿæ¯”ä¾‹
    neutral_ratio: float
    negative_ratio: float
    
    # ç»¼åˆæŒ‡æ ‡
    overall_heat: float  # 0-100
    signal_strength: int  # 0-100
    confidence: float  # 0-1


def aggregate_project_signals(project_name: str) -> ProjectSignal:
    """èšåˆé¡¹ç›®ä¿¡å·"""
    
    # 1. ç»Ÿè®¡å„å¹³å°æåŠ
    twitter_count = count_mentions(project_name, platform="twitter", hours=24)
    telegram_count = count_mentions(project_name, platform="telegram", hours=24)
    discord_count = count_mentions(project_name, platform="discord", hours=24)
    medium_count = count_mentions(project_name, platform="medium", days=7)
    reddit_count = count_mentions(project_name, platform="reddit", hours=24)
    
    # 2. è®¡ç®—å¢é•¿ç‡
    growth_24h = calculate_growth_rate(project_name, hours=24)
    growth_7d = calculate_growth_rate(project_name, days=7)
    
    # 3. ç»Ÿè®¡KOLæåŠ
    kol_mentions = count_kol_mentions_by_tier(project_name)
    
    # 4. è¯„è®ºåŒºæ•°æ®
    comment_data = get_comment_discoveries(project_name)
    
    # 5. æƒ…æ„Ÿåˆ†æ
    sentiment = aggregate_sentiment(project_name)
    
    # 6. è®¡ç®—ç»¼åˆçƒ­åº¦
    heat = calculate_topic_heat(project_name)
    
    # 7. è®¡ç®—ä¿¡å·å¼ºåº¦
    signal = calculate_signal_strength(
        mentions=twitter_count + telegram_count + discord_count,
        growth=growth_24h,
        kol_count=sum(kol_mentions.values()),
        sentiment=sentiment["positive_ratio"]
    )
    
    # 8. è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºæ•°æ®æ¥æºçš„å¤šæ ·æ€§ï¼‰
    sources = sum([
        twitter_count > 0,
        telegram_count > 0,
        discord_count > 0,
        medium_count > 0,
        reddit_count > 0
    ])
    confidence = min(1.0, sources / 3)  # è‡³å°‘3ä¸ªå¹³å°æ‰é«˜ç½®ä¿¡
    
    return ProjectSignal(
        project_name=project_name,
        twitter_mentions=twitter_count,
        telegram_mentions=telegram_count,
        discord_mentions=discord_count,
        medium_mentions=medium_count,
        reddit_mentions=reddit_count,
        mention_growth_24h=growth_24h,
        mention_growth_7d=growth_7d,
        kol_tier1_mentions=kol_mentions["tier1"],
        kol_tier2_mentions=kol_mentions["tier2"],
        kol_tier3_mentions=kol_mentions["tier3"],
        comment_discovery_count=comment_data["count"],
        avg_comment_quality=comment_data["avg_quality"],
        positive_ratio=sentiment["positive_ratio"],
        neutral_ratio=sentiment["neutral_ratio"],
        negative_ratio=sentiment["negative_ratio"],
        overall_heat=heat,
        signal_strength=signal,
        confidence=confidence
    )
```

---

## âœ… ç¬¬äºŒæ­¥: äº¤å‰éªŒè¯æœºåˆ¶

### 2.1 å¤šæºéªŒè¯

**ç›®æ ‡**: ç¡®ä¿é¡¹ç›®ä¸æ˜¯å•ä¸€æ¥æºçš„è™šå‡ç‚’ä½œ

```python
def cross_validate_project(project_name: str) -> dict:
    """äº¤å‰éªŒè¯é¡¹ç›®"""
    
    validation_result = {
        "project_name": project_name,
        "is_valid": False,
        "confidence": 0.0,
        "validation_details": {}
    }
    
    # éªŒè¯1: å®˜æ–¹ç½‘ç«™å­˜åœ¨ä¸”æœ‰æ•ˆ
    website = find_official_website(project_name)
    if website:
        domain_age = get_domain_age(website)
        ssl_valid = check_ssl(website)
        
        validation_result["validation_details"]["website"] = {
            "exists": True,
            "url": website,
            "domain_age_days": domain_age,
            "ssl_valid": ssl_valid,
            "score": min(20, domain_age / 10) if domain_age > 30 else 0
        }
    
    # éªŒè¯2: ç¤¾äº¤åª’ä½“è´¦å·çœŸå®æ€§
    social_accounts = find_social_accounts(project_name)
    
    twitter_valid = False
    if social_accounts.get("twitter"):
        twitter = get_twitter_account(social_accounts["twitter"])
        twitter_valid = (
            twitter["followers"] > 100 and
            twitter["tweets"] > 10 and
            twitter["age_days"] > 30
        )
        validation_result["validation_details"]["twitter"] = {
            "exists": True,
            "followers": twitter["followers"],
            "tweets": twitter["tweets"],
            "age_days": twitter["age_days"],
            "score": 20 if twitter_valid else 5
        }
    
    # éªŒè¯3: GitHubä»“åº“æ´»è·ƒ
    github = find_github_repo(project_name)
    if github:
        is_active = (
            github["commits_30d"] > 10 and
            github["contributors"] > 2
        )
        validation_result["validation_details"]["github"] = {
            "exists": True,
            "url": github["url"],
            "stars": github["stars"],
            "commits_30d": github["commits_30d"],
            "contributors": github["contributors"],
            "score": 25 if is_active else 10
        }
    
    # éªŒè¯4: èèµ„ä¿¡æ¯
    funding = check_funding_info(project_name)
    if funding:
        is_credible = verify_funding_sources(funding)
        validation_result["validation_details"]["funding"] = {
            "exists": True,
            "amount": funding["amount"],
            "investors": funding["investors"],
            "verified": is_credible,
            "score": 20 if is_credible else 5
        }
    
    # éªŒè¯5: åª’ä½“æŠ¥é“
    media_mentions = count_media_mentions(project_name)
    validation_result["validation_details"]["media"] = {
        "mention_count": media_mentions,
        "score": min(15, media_mentions * 3)
    }
    
    # è®¡ç®—æ€»åˆ†
    total_score = sum([
        detail.get("score", 0)
        for detail in validation_result["validation_details"].values()
    ])
    
    # åˆ¤æ–­æ˜¯å¦æœ‰æ•ˆ
    validation_result["is_valid"] = total_score >= 60
    validation_result["confidence"] = min(1.0, total_score / 100)
    
    return validation_result
```

### 2.2 è¯ˆéª—é¡¹ç›®è¯†åˆ«

**ç›®æ ‡**: è¿‡æ»¤æ‰éª—å±€é¡¹ç›®

```python
def detect_scam_signals(project_name: str) -> dict:
    """æ£€æµ‹è¯ˆéª—ä¿¡å·"""
    
    scam_score = 0  # åˆ†æ•°è¶Šé«˜è¶Šå¯ç–‘
    red_flags = []
    
    # çº¢æ——1: å›¢é˜ŸåŒ¿å
    team_info = get_team_info(project_name)
    if not team_info or len(team_info) == 0:
        scam_score += 20
        red_flags.append("å›¢é˜Ÿä¿¡æ¯ç¼ºå¤±æˆ–å®Œå…¨åŒ¿å")
    
    # çº¢æ——2: ä¸åˆç†çš„æ‰¿è¯º
    marketing_text = get_all_marketing_text(project_name)
    suspicious_keywords = [
        "guaranteed returns", "100x guaranteed", "get rich quick",
        "risk-free", "cannot lose", "guaranteed profit"
    ]
    
    for keyword in suspicious_keywords:
        if keyword in marketing_text.lower():
            scam_score += 15
            red_flags.append(f"åŒ…å«å¯ç–‘æ‰¿è¯º: '{keyword}'")
    
    # çº¢æ——3: æŠ„è¢­ç™½çš®ä¹¦
    whitepaper = get_whitepaper(project_name)
    if whitepaper:
        similarity = check_whitepaper_plagiarism(whitepaper)
        if similarity > 0.8:  # 80%ä»¥ä¸Šç›¸ä¼¼
            scam_score += 25
            red_flags.append(f"ç™½çš®ä¹¦ç–‘ä¼¼æŠ„è¢­ï¼ˆç›¸ä¼¼åº¦{similarity*100:.0f}%ï¼‰")
    
    # çº¢æ——4: åˆçº¦æœªå®¡è®¡
    contract = get_contract_address(project_name)
    if contract:
        audit_reports = check_audit_reports(contract)
        if not audit_reports:
            scam_score += 15
            red_flags.append("æ™ºèƒ½åˆçº¦æœªç»å®¡è®¡")
    
    # çº¢æ——5: ç¤¾äº¤åª’ä½“åˆ·é‡
    twitter = get_twitter_account(project_name)
    if twitter:
        bot_ratio = detect_bot_followers(twitter["username"])
        if bot_ratio > 0.5:  # è¶…è¿‡50%æœºå™¨äºº
            scam_score += 20
            red_flags.append(f"Twitterç²‰ä¸ç–‘ä¼¼åˆ·é‡ï¼ˆæœºå™¨äººæ¯”ä¾‹{bot_ratio*100:.0f}%ï¼‰")
    
    # çº¢æ——6: åŸŸå/è´¦å·å¹´é¾„è¿‡çŸ­
    website = find_official_website(project_name)
    if website:
        domain_age = get_domain_age(website)
        if domain_age < 7:  # ä¸åˆ°1å‘¨
            scam_score += 15
            red_flags.append(f"åŸŸåæ³¨å†Œæ—¶é—´è¿‡çŸ­ï¼ˆ{domain_age}å¤©ï¼‰")
    
    # çº¢æ——7: æµåŠ¨æ€§è¿‡ä½
    if contract:
        liquidity = get_liquidity(contract)
        if liquidity and liquidity < 10000:  # å°‘äº$10k
            scam_score += 10
            red_flags.append(f"æµåŠ¨æ€§è¿‡ä½ï¼ˆ${liquidity}ï¼‰")
    
    return {
        "project_name": project_name,
        "scam_score": scam_score,
        "is_likely_scam": scam_score >= 50,
        "risk_level": "High" if scam_score >= 50 else "Medium" if scam_score >= 30 else "Low",
        "red_flags": red_flags
    }
```

### 2.3 å·²å‘å¸é¡¹ç›®è¿‡æ»¤

**ç›®æ ‡**: æ’é™¤å·²ç»å‘å¸çš„é¡¹ç›®

```python
def check_token_status(project_name: str) -> dict:
    """æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²å‘å¸"""
    
    # æ–¹æ³•1: CoinGecko/CoinMarketCapæŸ¥è¯¢
    coingecko_result = search_coingecko(project_name)
    if coingecko_result:
        return {
            "has_token": True,
            "token_symbol": coingecko_result["symbol"],
            "token_address": coingecko_result["contract"],
            "market_cap": coingecko_result["market_cap"],
            "source": "CoinGecko"
        }
    
    # æ–¹æ³•2: DEXæŸ¥è¯¢ï¼ˆUniswap, PancakeSwapç­‰ï¼‰
    dex_result = search_dex_pairs(project_name)
    if dex_result:
        return {
            "has_token": True,
            "token_address": dex_result["token_address"],
            "dex": dex_result["dex_name"],
            "liquidity": dex_result["liquidity"],
            "source": "DEX"
        }
    
    # æ–¹æ³•3: å®˜æ–¹å£°æ˜æ£€æŸ¥
    official_announcement = search_token_announcement(project_name)
    if official_announcement:
        return {
            "has_token": True,
            "announcement_date": official_announcement["date"],
            "source": "Official"
        }
    
    # æ–¹æ³•4: åŒºå—æµè§ˆå™¨æœç´¢
    # ...
    
    return {
        "has_token": False,
        "checked_at": datetime.now()
    }
```

---

## ğŸ¤– ç¬¬ä¸‰æ­¥: AIç»¼åˆè¯„åˆ†ç³»ç»Ÿ

### 3.1 å…­ç»´åº¦è¯„åˆ†æ¨¡å‹

```python
class ProjectScore(BaseModel):
    """é¡¹ç›®ç»¼åˆè¯„åˆ†"""
    
    # å…­å¤§ç»´åº¦
    team_score: int  # å›¢é˜ŸèƒŒæ™¯ï¼ˆ0-100ï¼‰
    tech_score: int  # æŠ€æœ¯åˆ›æ–°ï¼ˆ0-100ï¼‰
    community_score: int  # ç¤¾åŒºçƒ­åº¦ï¼ˆ0-100ï¼‰
    tokenomics_score: int  # ä»£å¸ç»æµï¼ˆ0-100ï¼‰
    market_score: int  # å¸‚åœºæ—¶æœºï¼ˆ0-100ï¼‰
    risk_score: int  # é£é™©è¯„ä¼°ï¼ˆ0-100ï¼Œåˆ†æ•°è¶Šé«˜é£é™©è¶Šä½ï¼‰
    
    # ç»¼åˆå¾—åˆ†
    composite_score: int  # åŠ æƒç»¼åˆåˆ†ï¼ˆ0-100ï¼‰
    
    # åˆ†çº§
    grade: str  # S/A/B/C
    
    # æ¨èåº¦
    recommendation: str  # Strong Buy, Buy, Hold, Pass


def calculate_comprehensive_score(project_name: str) -> ProjectScore:
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    
    # 1. å›¢é˜ŸèƒŒæ™¯è¯„åˆ†ï¼ˆæƒé‡20%ï¼‰
    team_score = assess_team_background(project_name)
    
    # 2. æŠ€æœ¯åˆ›æ–°è¯„åˆ†ï¼ˆæƒé‡25%ï¼‰
    tech_score = assess_technical_innovation(project_name)
    
    # 3. ç¤¾åŒºçƒ­åº¦è¯„åˆ†ï¼ˆæƒé‡20%ï¼‰
    community_score = assess_community_heat(project_name)
    
    # 4. ä»£å¸ç»æµè¯„åˆ†ï¼ˆæƒé‡15%ï¼‰
    tokenomics_score = assess_tokenomics(project_name)
    
    # 5. å¸‚åœºæ—¶æœºè¯„åˆ†ï¼ˆæƒé‡10%ï¼‰
    market_score = assess_market_timing(project_name)
    
    # 6. é£é™©è¯„ä¼°è¯„åˆ†ï¼ˆæƒé‡10%ï¼‰
    risk_score = assess_risks(project_name)
    
    # è®¡ç®—åŠ æƒç»¼åˆåˆ†
    composite = (
        team_score * 0.20 +
        tech_score * 0.25 +
        community_score * 0.20 +
        tokenomics_score * 0.15 +
        market_score * 0.10 +
        risk_score * 0.10
    )
    
    # è‡´å‘½é£é™©é™çº§
    scam_check = detect_scam_signals(project_name)
    if scam_check["is_likely_scam"]:
        composite *= 0.5  # é™50%
    
    # é¡¶çº§VCåŠ åˆ†
    if has_top_tier_vc(project_name):
        composite += 5
    
    composite = max(0, min(100, composite))
    
    # ç¡®å®šåˆ†çº§
    if composite >= 85:
        grade = "S"
        recommendation = "Strong Buy"
    elif composite >= 70:
        grade = "A"
        recommendation = "Buy"
    elif composite >= 55:
        grade = "B"
        recommendation = "Hold"
    else:
        grade = "C"
        recommendation = "Pass"
    
    return ProjectScore(
        team_score=int(team_score),
        tech_score=int(tech_score),
        community_score=int(community_score),
        tokenomics_score=int(tokenomics_score),
        market_score=int(market_score),
        risk_score=int(risk_score),
        composite_score=int(composite),
        grade=grade,
        recommendation=recommendation
    )
```

### 3.2 å›¢é˜ŸèƒŒæ™¯è¯„åˆ†

```python
def assess_team_background(project_name: str) -> float:
    """è¯„ä¼°å›¢é˜ŸèƒŒæ™¯ï¼ˆ0-100åˆ†ï¼‰"""
    
    score = 0
    team_info = get_team_info(project_name)
    
    if not team_info:
        return 0  # å›¢é˜Ÿä¿¡æ¯ç¼ºå¤±
    
    # å› å­1: å›¢é˜Ÿæˆå‘˜æ•°é‡ï¼ˆ15åˆ†ï¼‰
    team_size = len(team_info)
    score += min(15, team_size * 3)  # 5äººå›¢é˜Ÿæ»¡åˆ†
    
    # å› å­2: æˆå‘˜èƒŒæ™¯ï¼ˆ40åˆ†ï¼‰
    for member in team_info:
        # FAANGèƒŒæ™¯
        if member.get("previous_companies"):
            faang = ["Google", "Facebook", "Amazon", "Apple", "Microsoft"]
            if any(company in member["previous_companies"] for company in faang):
                score += 8
        
        # Web3æˆåŠŸé¡¹ç›®ç»éªŒ
        if member.get("previous_web3_projects"):
            successful = [p for p in member["previous_web3_projects"] if p["success"]]
            score += len(successful) * 5
        
        # å­¦å†
        if member.get("education"):
            top_schools = ["MIT", "Stanford", "CMU", "Berkeley", "ETH Zurich"]
            if any(school in member["education"] for school in top_schools):
                score += 3
    
    score = min(score, 40)  # è¿™éƒ¨åˆ†æœ€é«˜40åˆ†
    
    # å› å­3: å›¢é˜Ÿå®Œæ•´æ€§ï¼ˆ20åˆ†ï¼‰
    roles = [m.get("role") for m in team_info]
    required_roles = ["CEO", "CTO", "CMO"]  # æ ¸å¿ƒè§’è‰²
    completeness = sum([1 for role in required_roles if role in roles]) / len(required_roles)
    score += completeness * 20
    
    # å› å­4: ç¤¾äº¤åª’ä½“æ´»è·ƒåº¦ï¼ˆ15åˆ†ï¼‰
    for member in team_info:
        if member.get("twitter"):
            twitter = get_twitter_account(member["twitter"])
            if twitter["followers"] > 10000:
                score += 5
    
    score = min(score, 15)
    
    # å› å­5: å›¢é˜Ÿé€æ˜åº¦ï¼ˆ10åˆ†ï¼‰
    # å…¬å¼€LinkedInã€ç…§ç‰‡ã€è¯¦ç»†ç®€å†
    transparency = sum([
        member.get("linkedin") is not None,
        member.get("photo") is not None,
        member.get("bio") is not None
    ]) / (len(team_info) * 3)
    
    score += transparency * 10
    
    return min(100, score)
```

### 3.3 æŠ€æœ¯åˆ›æ–°è¯„åˆ†

```python
def assess_technical_innovation(project_name: str) -> float:
    """è¯„ä¼°æŠ€æœ¯åˆ›æ–°ï¼ˆ0-100åˆ†ï¼‰"""
    
    score = 0
    
    # å› å­1: GitHubæ´»è·ƒåº¦ï¼ˆ30åˆ†ï¼‰
    github = find_github_repo(project_name)
    if github:
        # ä»£ç æäº¤é¢‘ç‡
        commits_30d = github["commits_30d"]
        score += min(10, commits_30d / 10)
        
        # è´¡çŒ®è€…æ•°é‡
        contributors = github["contributors"]
        score += min(10, contributors * 2)
        
        # ä»£ç è´¨é‡
        code_quality = analyze_code_quality(github["url"])
        score += code_quality * 10  # 0-1æ˜ å°„åˆ°0-10
    
    # å› å­2: æŠ€æœ¯æ–‡æ¡£è´¨é‡ï¼ˆ20åˆ†ï¼‰
    docs = get_technical_docs(project_name)
    if docs:
        doc_score = assess_docs_quality(docs)
        score += doc_score * 20
    
    # å› å­3: æŠ€æœ¯åˆ›æ–°æ€§ï¼ˆ30åˆ†ï¼‰
    whitepaper = get_whitepaper(project_name)
    if whitepaper:
        innovation = ai_assess_innovation(whitepaper)
        score += innovation * 30
    
    # å› å­4: å®‰å…¨å®¡è®¡ï¼ˆ20åˆ†ï¼‰
    contract = get_contract_address(project_name)
    if contract:
        audits = check_audit_reports(contract)
        if audits:
            # æœ‰å®¡è®¡æŠ¥å‘Š
            score += 10
            
            # é¡¶çº§å®¡è®¡å…¬å¸åŠ åˆ†
            top_auditors = ["Certik", "Trail of Bits", "OpenZeppelin"]
            if any(auditor in audits for auditor in top_auditors):
                score += 10
    
    return min(100, score)


def ai_assess_innovation(whitepaper_text: str) -> float:
    """AIè¯„ä¼°æŠ€æœ¯åˆ›æ–°æ€§ï¼ˆ0-1ï¼‰"""
    
    prompt = f"""
    è¯·è¯„ä¼°ä»¥ä¸‹Web3é¡¹ç›®ç™½çš®ä¹¦çš„æŠ€æœ¯åˆ›æ–°æ€§ã€‚
    è¯„åˆ†æ ‡å‡†ï¼š
    - 0.9-1.0: é©å‘½æ€§åˆ›æ–°ï¼Œå…¨æ–°æŠ€æœ¯èŒƒå¼
    - 0.7-0.9: é‡å¤§åˆ›æ–°ï¼Œæ˜¾è‘—æŠ€æœ¯çªç ´
    - 0.5-0.7: æ¸è¿›å¼åˆ›æ–°ï¼Œæœ‰æŠ€æœ¯æ”¹è¿›
    - 0.3-0.5: å°å¹…åˆ›æ–°ï¼Œä¸»è¦æ˜¯å·¥ç¨‹ä¼˜åŒ–
    - 0.0-0.3: æ— æ˜æ˜¾åˆ›æ–°ï¼ŒæŠ„è¢­æˆ–ç®€å•å¤åˆ¶
    
    åªè¿”å›0-1ä¹‹é—´çš„æ•°å­—ã€‚
    
    ç™½çš®ä¹¦å†…å®¹ï¼š
    {whitepaper_text[:5000]}
    
    åˆ›æ–°æ€§è¯„åˆ†ï¼š
    """
    
    response = call_ai_api(prompt, model="gpt-4")
    
    try:
        score = float(response.strip())
        return max(0, min(1, score))
    except:
        return 0.5  # é»˜è®¤ä¸­ç­‰
```

### 3.4 ç¤¾åŒºçƒ­åº¦è¯„åˆ†

```python
def assess_community_heat(project_name: str) -> float:
    """è¯„ä¼°ç¤¾åŒºçƒ­åº¦ï¼ˆ0-100åˆ†ï¼‰"""
    
    score = 0
    
    # å› å­1: Twitterç²‰ä¸ä¸äº’åŠ¨ï¼ˆ30åˆ†ï¼‰
    twitter = get_twitter_account(project_name)
    if twitter:
        # ç²‰ä¸æ•°
        followers = twitter["followers"]
        score += min(15, followers / 10000 * 15)  # 10ä¸‡ç²‰ä¸æ»¡åˆ†
        
        # äº’åŠ¨ç‡
        engagement_rate = twitter["avg_engagement"] / twitter["followers"]
        score += min(15, engagement_rate * 100 * 15)  # äº’åŠ¨ç‡10%æ»¡åˆ†
    
    # å› å­2: Telegramæˆå‘˜ä¸æ´»è·ƒåº¦ï¼ˆ25åˆ†ï¼‰
    telegram = get_telegram_info(project_name)
    if telegram:
        # æˆå‘˜æ•°
        members = telegram["member_count"]
        score += min(15, members / 5000 * 15)  # 5ä¸‡æˆå‘˜æ»¡åˆ†
        
        # æ´»è·ƒåº¦
        daily_messages = telegram["daily_messages"]
        score += min(10, daily_messages / 1000 * 10)  # 1000æ¡/å¤©æ»¡åˆ†
    
    # å› å­3: Discordæ´»è·ƒåº¦ï¼ˆ25åˆ†ï¼‰
    discord = get_discord_info(project_name)
    if discord:
        activity_score = discord["activity_score"]
        score += activity_score * 0.25
    
    # å› å­4: å¢é•¿è¶‹åŠ¿ï¼ˆ20åˆ†ï¼‰
    growth = calculate_community_growth(project_name, days=30)
    
    # Twitterå¢é•¿
    twitter_growth = growth["twitter_followers_growth"]
    score += min(10, twitter_growth * 100)  # 10%å¢é•¿æ»¡åˆ†
    
    # Telegramå¢é•¿
    telegram_growth = growth["telegram_members_growth"]
    score += min(10, telegram_growth * 100)
    
    return min(100, score)
```

### 3.5 å‘å¸æ¦‚ç‡é¢„æµ‹

```python
def predict_token_launch_probability(project_name: str) -> dict:
    """é¢„æµ‹é¡¹ç›®å‘å¸æ¦‚ç‡"""
    
    probability = 0
    signals = []
    estimated_timeline = None
    
    # å¼ºä¿¡å·ï¼ˆæ¯ä¸ª+15%æ¦‚ç‡ï¼‰
    
    # 1. å®˜æ–¹å®£å¸ƒå¿«ç…§æ—¶é—´
    if check_snapshot_announcement(project_name):
        probability += 15
        signals.append("å·²å®£å¸ƒå¿«ç…§æ—¶é—´")
        estimated_timeline = "1-2å‘¨å†…"
    
    # 2. Tokenomicsæ–‡æ¡£å‘å¸ƒ
    if check_tokenomics_published(project_name):
        probability += 15
        signals.append("ä»£å¸ç»æµå­¦å·²å…¬å¼€")
    
    # 3. ç§¯åˆ†ç³»ç»Ÿè¿è¡Œä¸­
    if check_points_system(project_name):
        probability += 12
        signals.append("ç§¯åˆ†ç³»ç»Ÿè¿è¡Œä¸­")
        if not estimated_timeline:
            estimated_timeline = "1-3ä¸ªæœˆå†…"
    
    # 4. å®Œæˆå®¡è®¡
    if check_audit_completed(project_name):
        probability += 10
        signals.append("æ™ºèƒ½åˆçº¦å®¡è®¡å®Œæˆ")
    
    # ä¸­ç­‰ä¿¡å·ï¼ˆæ¯ä¸ª+8%æ¦‚ç‡ï¼‰
    
    # 5. ä¸»ç½‘å·²ä¸Šçº¿
    if check_mainnet_status(project_name):
        probability += 8
        signals.append("ä¸»ç½‘å·²ä¸Šçº¿")
        if not estimated_timeline:
            estimated_timeline = "3-6ä¸ªæœˆå†…"
    
    # 6. å®Œæˆå¤§é¢èèµ„
    funding = check_funding_info(project_name)
    if funding and funding["amount"] > 20_000_000:  # >$20M
        probability += 8
        signals.append(f"å®Œæˆ${funding['amount']/1e6:.0f}Mèèµ„")
    
    # 7. æ‹›è˜Tokenomicsç›¸å…³èŒä½
    if check_tokenomics_hiring(project_name):
        probability += 6
        signals.append("æ­£åœ¨æ‹›è˜ä»£å¸ç»æµå­¦è®¾è®¡å¸ˆ")
    
    # å¼±ä¿¡å·ï¼ˆæ¯ä¸ª+5%æ¦‚ç‡ï¼‰
    
    # 8. ç«å“åˆšå‘å¸
    competitors = find_competitors(project_name)
    recent_launches = [c for c in competitors if c["token_launch_date"] > datetime.now() - timedelta(days=90)]
    if recent_launches:
        probability += 5
        signals.append("ç«å“æœ€è¿‘å‘å¸ï¼Œå¯èƒ½è·Ÿè¿›")
    
    # 9. è·¯çº¿å›¾æåŠä»£å¸
    roadmap = get_roadmap(project_name)
    if roadmap and "token" in roadmap.lower():
        probability += 5
        signals.append("è·¯çº¿å›¾æåŠä»£å¸")
    
    # 10. å®˜æ–¹ç¤¾äº¤åª’ä½“é«˜é¢‘æåŠ"soon"
    recent_posts = get_recent_social_posts(project_name, days=30)
    soon_count = sum([1 for post in recent_posts if "soon" in post.lower()])
    if soon_count > 5:
        probability += 5
        signals.append("å®˜æ–¹é¢‘ç¹æš—ç¤º'å³å°†æ¨å‡º'")
    
    # è´Ÿé¢ä¿¡å·ï¼ˆé™ä½æ¦‚ç‡ï¼‰
    
    # å›¢é˜Ÿæ˜ç¡®è¡¨ç¤ºçŸ­æœŸä¸å‘å¸
    if check_no_token_statement(project_name):
        probability *= 0.5
        signals.append("âš ï¸ å›¢é˜Ÿè¡¨ç¤ºçŸ­æœŸä¸è€ƒè™‘å‘å¸")
    
    probability = min(100, probability)
    
    # ç¡®å®šç½®ä¿¡åŒºé—´
    if probability >= 80:
        confidence = "Very High"
        timeline = estimated_timeline or "1-2ä¸ªæœˆå†…"
    elif probability >= 60:
        confidence = "High"
        timeline = estimated_timeline or "2-4ä¸ªæœˆå†…"
    elif probability >= 40:
        confidence = "Medium"
        timeline = estimated_timeline or "4-6ä¸ªæœˆå†…"
    elif probability >= 20:
        confidence = "Low"
        timeline = estimated_timeline or "6-12ä¸ªæœˆå†…"
    else:
        confidence = "Very Low"
        timeline = "æœªçŸ¥æˆ–12ä¸ªæœˆä»¥ä¸Š"
    
    return {
        "project_name": project_name,
        "launch_probability": probability,
        "confidence": confidence,
        "estimated_timeline": timeline,
        "detected_signals": signals,
        "signal_count": len(signals)
    }
```

### 3.6 ç©ºæŠ•ä»·å€¼ä¼°ç®—

```python
def estimate_airdrop_value(project_name: str) -> dict:
    """ä¼°ç®—ç©ºæŠ•ä»·å€¼"""
    
    # 1. æ‰¾åˆ°ç›¸ä¼¼çš„å†å²é¡¹ç›®
    similar_projects = find_similar_historical_projects(project_name)
    
    if not similar_projects:
        return {
            "estimated_value_usd": 0,
            "confidence": "Low",
            "method": "No similar cases"
        }
    
    # 2. åŸºäºå†å²æ¡ˆä¾‹è®¡ç®—
    historical_values = []
    
    for project in similar_projects:
        # è·å–è¯¥é¡¹ç›®çš„ç©ºæŠ•æ•°æ®
        airdrop_data = get_historical_airdrop(project["name"])
        
        if airdrop_data:
            # è°ƒæ•´ç³»æ•°ï¼ˆåŸºäºé¡¹ç›®è§„æ¨¡å·®å¼‚ï¼‰
            adjustment = calculate_scale_adjustment(project_name, project["name"])
            
            adjusted_value = airdrop_data["avg_value_per_user"] * adjustment
            historical_values.append(adjusted_value)
    
    # 3. å–ä¸­ä½æ•°ä½œä¸ºä¼°å€¼
    if historical_values:
        estimated_value = sorted(historical_values)[len(historical_values) // 2]
    else:
        estimated_value = 0
    
    # 4. è®¡ç®—ç½®ä¿¡åº¦
    confidence = "High" if len(historical_values) >= 3 else "Medium" if len(historical_values) >= 2 else "Low"
    
    return {
        "project_name": project_name,
        "estimated_value_usd": int(estimated_value),
        "value_range_usd": {
            "min": int(min(historical_values)) if historical_values else 0,
            "max": int(max(historical_values)) if historical_values else 0
        },
        "confidence": confidence,
        "reference_cases": [p["name"] for p in similar_projects],
        "calculation_method": "Historical Comparison"
    }


def find_similar_historical_projects(project_name: str) -> List[dict]:
    """æ‰¾åˆ°ç›¸ä¼¼çš„å†å²é¡¹ç›®"""
    
    # è·å–ç›®æ ‡é¡¹ç›®ç‰¹å¾
    target_features = extract_project_features(project_name)
    
    # å†å²æˆåŠŸæ¡ˆä¾‹åº“
    historical_cases = load_historical_airdrop_cases()
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarities = []
    
    for case in historical_cases:
        case_features = extract_project_features(case["name"])
        similarity = calculate_feature_similarity(target_features, case_features)
        
        similarities.append({
            "name": case["name"],
            "similarity": similarity,
            "airdrop_data": case["airdrop"]
        })
    
    # è¿”å›æœ€ç›¸ä¼¼çš„3ä¸ª
    similarities.sort(key=lambda x: x["similarity"], reverse=True)
    return similarities[:3]


def extract_project_features(project_name: str) -> dict:
    """æå–é¡¹ç›®ç‰¹å¾"""
    
    return {
        "category": get_project_category(project_name),  # DeFi, NFT, GameFiç­‰
        "tvl": get_tvl(project_name) or 0,
        "user_count": get_user_count(project_name) or 0,
        "funding_amount": get_funding_amount(project_name) or 0,
        "community_size": get_community_size(project_name) or 0,
        "age_days": get_project_age(project_name) or 0,
    }


def calculate_feature_similarity(features1: dict, features2: dict) -> float:
    """è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰"""
    
    similarity = 0
    
    # ç±»åˆ«ç›¸åŒï¼ˆæƒé‡30%ï¼‰
    if features1["category"] == features2["category"]:
        similarity += 0.3
    
    # TVLç›¸ä¼¼åº¦ï¼ˆæƒé‡25%ï¼‰
    if features1["tvl"] > 0 and features2["tvl"] > 0:
        tvl_ratio = min(features1["tvl"], features2["tvl"]) / max(features1["tvl"], features2["tvl"])
        similarity += 0.25 * tvl_ratio
    
    # ç”¨æˆ·æ•°ç›¸ä¼¼åº¦ï¼ˆæƒé‡20%ï¼‰
    if features1["user_count"] > 0 and features2["user_count"] > 0:
        user_ratio = min(features1["user_count"], features2["user_count"]) / max(features1["user_count"], features2["user_count"])
        similarity += 0.20 * user_ratio
    
    # èèµ„é¢ç›¸ä¼¼åº¦ï¼ˆæƒé‡15%ï¼‰
    if features1["funding_amount"] > 0 and features2["funding_amount"] > 0:
        funding_ratio = min(features1["funding_amount"], features2["funding_amount"]) / max(features1["funding_amount"], features2["funding_amount"])
        similarity += 0.15 * funding_ratio
    
    # ç¤¾åŒºè§„æ¨¡ç›¸ä¼¼åº¦ï¼ˆæƒé‡10%ï¼‰
    if features1["community_size"] > 0 and features2["community_size"] > 0:
        community_ratio = min(features1["community_size"], features2["community_size"]) / max(features1["community_size"], features2["community_size"])
        similarity += 0.10 * community_ratio
    
    return similarity
```

---

## ğŸ“ˆ ç¬¬å››æ­¥: åˆ†çº§ä¸æ¨é€ç­–ç•¥

### 4.1 é¡¹ç›®åˆ†çº§æ ‡å‡†

```python
def classify_project(score: ProjectScore, launch_prob: dict, airdrop_value: dict) -> dict:
    """é¡¹ç›®åˆ†çº§"""
    
    # ç»¼åˆè¯„åˆ†
    composite = score.composite_score
    
    # å‘å¸æ¦‚ç‡
    probability = launch_prob["launch_probability"]
    
    # ç©ºæŠ•ä»·å€¼
    value = airdrop_value["estimated_value_usd"]
    
    # åˆ†çº§é€»è¾‘
    if composite >= 85 and probability >= 80:
        tier = "S"
        priority = "Critical"
        action = "ç«‹å³æ¨é€ + ç«‹å³å‚ä¸"
        
    elif composite >= 70 and probability >= 60:
        tier = "A"
        priority = "High"
        action = "æ¯æ—¥æŠ¥å‘Š + ä¼˜å…ˆå‚ä¸"
        
    elif composite >= 55 and probability >= 40:
        tier = "B"
        priority = "Medium"
        action = "æ¯æ—¥æŠ¥å‘Š + è§‚å¯Ÿ"
        
    else:
        tier = "C"
        priority = "Low"
        action = "ä»…è®°å½•ï¼Œä¸æ¨é€"
    
    # ç‰¹æ®Šæå‡ï¼šç©ºæŠ•ä»·å€¼ç‰¹åˆ«é«˜
    if value > 5000 and tier in ["B", "C"]:
        tier = "A"
        priority = "High"
        action = "é«˜ä»·å€¼ç©ºæŠ•ï¼Œå‡çº§æ¨é€"
    
    return {
        "tier": tier,
        "priority": priority,
        "recommended_action": action,
        "rationale": generate_rationale(score, launch_prob, airdrop_value)
    }
```

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- âœ… èƒ½å¤Ÿä»å¤šå¹³å°å‘ç°æ–°é¡¹ç›®ï¼ˆæ—¥å‘ç° > 50ä¸ªï¼‰
- âœ… èƒ½å¤Ÿè®¡ç®—é¡¹ç›®è¯é¢˜çƒ­åº¦
- âœ… èƒ½å¤Ÿä»è¯„è®ºåŒºæå–é¡¹ç›®æåŠ
- âœ… èƒ½å¤Ÿäº¤å‰éªŒè¯é¡¹ç›®çœŸå®æ€§
- âœ… èƒ½å¤Ÿè¯†åˆ«è¯ˆéª—é¡¹ç›®ï¼ˆå‡†ç¡®ç‡ > 85%ï¼‰
- âœ… èƒ½å¤Ÿè¿‡æ»¤å·²å‘å¸é¡¹ç›®
- âœ… èƒ½å¤Ÿè¿›è¡Œå…­ç»´åº¦è¯„åˆ†
- âœ… èƒ½å¤Ÿé¢„æµ‹å‘å¸æ¦‚ç‡
- âœ… èƒ½å¤Ÿä¼°ç®—ç©ºæŠ•ä»·å€¼
- âœ… èƒ½å¤Ÿè¿›è¡Œé¡¹ç›®åˆ†çº§

### æ€§èƒ½éªŒæ”¶

- âœ… å•é¡¹ç›®å®Œæ•´è¯„ä¼°æ—¶é—´ < 5åˆ†é’Ÿ
- âœ… æ‰¹é‡è¯„ä¼°ï¼ˆ50ä¸ªé¡¹ç›®ï¼‰æ—¶é—´ < 1å°æ—¶
- âœ… Sçº§é¡¹ç›®å‘ç°åæ¨é€å»¶è¿Ÿ < 10åˆ†é’Ÿ

### è´¨é‡éªŒæ”¶

- âœ… é¡¹ç›®å‘ç°å‡†ç¡®ç‡ > 80%ï¼ˆçœŸå®é¡¹ç›® vs å™ªéŸ³ï¼‰
- âœ… è¯„åˆ†ä¸å®é™…è¡¨ç°ç›¸å…³æ€§ > 0.7
- âœ… å‘å¸æ¦‚ç‡é¢„æµ‹å‡†ç¡®ç‡ > 70%
- âœ… ç©ºæŠ•ä»·å€¼ä¼°ç®—è¯¯å·® < 50%
- âœ… Sçº§é¡¹ç›®ä¸­ï¼Œ3ä¸ªæœˆå†…å‘å¸ç‡ > 80%

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-04  
**è´Ÿè´£äºº**: äº§å“ç»ç†

