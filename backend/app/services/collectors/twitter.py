"""Twitteræ•°æ®é‡‡é›†æœåŠ¡"""

import re
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from loguru import logger
import tweepy
from app.core.config import settings


class TwitterCollector:
    """Twitteræ•°æ®é‡‡é›†å™¨"""
    
    # ç›‘æ§çš„å…³é”®è¯åˆ—è¡¨
    KEYWORDS = [
        "presale",
        "fair launch",
        "new token",
        "airdrop",
        "testnet",
        "mainnet launch",
        "IDO",
        "ICO",
        "token sale",
        "Web3",
        "DeFi",
        "NFT mint",
    ]
    
    # é¡¶çº§åŠ å¯†KOLåˆ—è¡¨
    TOP_KOLS = [
        "VitalikButerin",
        "aantonop",
        "CZ_Binance",
        "SBF_FTX",
        "brian_armstrong",
        "justinsuntron",
        "APompliano",
        "TheCryptoLark",
        "inversebrah",
        "CryptoWendyO",
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–Twitterå®¢æˆ·ç«¯"""
        if not settings.TWITTER_BEARER_TOKEN:
            logger.warning("Twitter Bearer Token not configured")
            self.client = None
            return
            
        try:
            self.client = tweepy.Client(
                bearer_token=settings.TWITTER_BEARER_TOKEN,
                wait_on_rate_limit=True
            )
            logger.info("âœ… Twitter client initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Twitter client: {e}")
            self.client = None
    
    def search_recent_tweets(
        self,
        query: str,
        max_results: int = 100,
        hours: int = 24
    ) -> List[Dict]:
        """æœç´¢æœ€è¿‘çš„æ¨æ–‡
        
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•° (10-100)
            hours: æœç´¢è¿‡å»Nå°æ—¶çš„æ¨æ–‡
            
        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        if not self.client:
            logger.warning("Twitter client not available")
            return []
        
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = datetime.utcnow() - timedelta(hours=hours)
            
            # æœç´¢æ¨æ–‡
            tweets = self.client.search_recent_tweets(
                query=query,
                max_results=max_results,
                start_time=start_time,
                tweet_fields=["created_at", "public_metrics", "author_id", "entities"],
                expansions=["author_id"],
                user_fields=["username", "verified", "public_metrics"]
            )
            
            if not tweets.data:
                logger.info(f"No tweets found for query: {query}")
                return []
            
            # è§£ææ¨æ–‡æ•°æ®
            results = []
            users = {user.id: user for user in tweets.includes.get("users", [])}
            
            for tweet in tweets.data:
                author = users.get(tweet.author_id)
                
                result = {
                    "tweet_id": tweet.id,
                    "text": tweet.text,
                    "created_at": tweet.created_at,
                    "author_id": tweet.author_id,
                    "author_username": author.username if author else None,
                    "author_verified": author.verified if author else False,
                    "author_followers": author.public_metrics["followers_count"] if author else 0,
                    "likes": tweet.public_metrics["like_count"],
                    "retweets": tweet.public_metrics["retweet_count"],
                    "replies": tweet.public_metrics["reply_count"],
                    "entities": tweet.entities if hasattr(tweet, "entities") else {},
                }
                
                results.append(result)
            
            logger.info(f"âœ… Found {len(results)} tweets for query: {query}")
            return results
            
        except Exception as e:
            logger.error(f"Error searching tweets: {e}")
            return []
    
    def monitor_keywords(self, hours: int = 1) -> List[Dict]:
        """ç›‘æ§å…³é”®è¯ç›¸å…³æ¨æ–‡
        
        Args:
            hours: ç›‘æ§è¿‡å»Nå°æ—¶
            
        Returns:
            æ‰€æœ‰å…³é”®è¯çš„æ¨æ–‡åˆ—è¡¨
        """
        all_tweets = []
        
        for keyword in self.KEYWORDS:
            # æ„å»ºæŸ¥è¯¢(æ’é™¤è½¬å‘)
            query = f"{keyword} -is:retweet lang:en"
            
            tweets = self.search_recent_tweets(
                query=query,
                max_results=50,
                hours=hours
            )
            
            # æ ‡è®°å…³é”®è¯
            for tweet in tweets:
                tweet["matched_keyword"] = keyword
            
            all_tweets.extend(tweets)
        
        logger.info(f"âœ… Total tweets collected: {len(all_tweets)}")
        return all_tweets
    
    def track_kol_tweets(self, username: str, max_results: int = 10) -> List[Dict]:
        """è¿½è¸ªKOLçš„æœ€æ–°æ¨æ–‡
        
        Args:
            username: Twitterç”¨æˆ·å
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        if not self.client:
            return []
        
        try:
            # è·å–ç”¨æˆ·
            user = self.client.get_user(username=username)
            if not user.data:
                logger.warning(f"User not found: {username}")
                return []
            
            user_id = user.data.id
            
            # è·å–ç”¨æˆ·æ¨æ–‡
            tweets = self.client.get_users_tweets(
                id=user_id,
                max_results=max_results,
                tweet_fields=["created_at", "public_metrics", "entities"],
                exclude=["retweets", "replies"]  # åªè¦åŸåˆ›æ¨æ–‡
            )
            
            if not tweets.data:
                return []
            
            results = []
            for tweet in tweets.data:
                result = {
                    "tweet_id": tweet.id,
                    "text": tweet.text,
                    "created_at": tweet.created_at,
                    "author_username": username,
                    "likes": tweet.public_metrics["like_count"],
                    "retweets": tweet.public_metrics["retweet_count"],
                    "replies": tweet.public_metrics["reply_count"],
                    "entities": tweet.entities if hasattr(tweet, "entities") else {},
                }
                results.append(result)
            
            logger.info(f"âœ… Collected {len(results)} tweets from @{username}")
            return results
            
        except Exception as e:
            logger.error(f"Error tracking KOL {username}: {e}")
            return []
    
    def track_all_kols(self) -> List[Dict]:
        """è¿½è¸ªæ‰€æœ‰é¡¶çº§KOLçš„æ¨æ–‡
        
        Returns:
            æ‰€æœ‰KOLçš„æ¨æ–‡åˆ—è¡¨
        """
        all_tweets = []
        
        for username in self.TOP_KOLS:
            tweets = self.track_kol_tweets(username, max_results=10)
            
            # æ ‡è®°ä¸ºKOLæ¨æ–‡
            for tweet in tweets:
                tweet["is_kol_tweet"] = True
                tweet["kol_username"] = username
            
            all_tweets.extend(tweets)
        
        logger.info(f"âœ… Total KOL tweets collected: {len(all_tweets)}")
        return all_tweets
    
    def extract_project_info(self, tweet: Dict) -> Optional[Dict]:
        """ä»æ¨æ–‡ä¸­æå–é¡¹ç›®ä¿¡æ¯
        
        Args:
            tweet: æ¨æ–‡æ•°æ®
            
        Returns:
            é¡¹ç›®ä¿¡æ¯å­—å…¸ or None
        """
        text = tweet["text"]
        entities = tweet.get("entities", {})
        
        # æå–URL
        urls = []
        if "urls" in entities:
            urls = [url["expanded_url"] for url in entities["urls"]]
        
        # æå–æåŠçš„ç”¨æˆ·
        mentions = []
        if "mentions" in entities:
            mentions = [mention["username"] for mention in entities["mentions"]]
        
        # æå–hashtags
        hashtags = []
        if "hashtags" in entities:
            hashtags = [tag["tag"] for tag in entities["hashtags"]]
        
        # å°è¯•æå–åˆçº¦åœ°å€(ä»¥å¤ªåŠåœ°å€æ ¼å¼)
        contract_pattern = r"0x[a-fA-F0-9]{40}"
        contracts = re.findall(contract_pattern, text)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜æ˜¾çš„é¡¹ç›®ä¿¡æ¯ï¼Œè¿”å›None
        if not urls and not contracts and not hashtags:
            return None
        
        return {
            "tweet_id": tweet["tweet_id"],
            "discovered_at": tweet["created_at"],
            "source": "twitter",
            "source_url": f"https://twitter.com/{tweet.get('author_username')}/status/{tweet['tweet_id']}",
            "text": text,
            "urls": urls,
            "contracts": contracts,
            "hashtags": hashtags,
            "mentions": mentions,
            "engagement": {
                "likes": tweet["likes"],
                "retweets": tweet["retweets"],
                "replies": tweet["replies"],
            },
            "author": {
                "username": tweet.get("author_username"),
                "verified": tweet.get("author_verified", False),
                "followers": tweet.get("author_followers", 0),
            }
        }
    
    def collect_and_extract(self, hours: int = 1) -> List[Dict]:
        """é‡‡é›†æ¨æ–‡å¹¶æå–é¡¹ç›®ä¿¡æ¯
        
        Args:
            hours: ç›‘æ§è¿‡å»Nå°æ—¶
            
        Returns:
            é¡¹ç›®ä¿¡æ¯åˆ—è¡¨
        """
        logger.info(f"ğŸ” Starting Twitter collection (last {hours} hours)...")
        
        # 1. ç›‘æ§å…³é”®è¯
        keyword_tweets = self.monitor_keywords(hours=hours)
        
        # 2. è¿½è¸ªKOL
        kol_tweets = self.track_all_kols()
        
        # 3. åˆå¹¶å»é‡
        all_tweets = keyword_tweets + kol_tweets
        unique_tweets = {tweet["tweet_id"]: tweet for tweet in all_tweets}
        
        logger.info(f"ğŸ“Š Collected {len(unique_tweets)} unique tweets")
        
        # 4. æå–é¡¹ç›®ä¿¡æ¯
        projects = []
        for tweet in unique_tweets.values():
            project_info = self.extract_project_info(tweet)
            if project_info:
                projects.append(project_info)
        
        logger.info(f"âœ… Extracted {len(projects)} potential projects")
        return projects


# å…¨å±€é‡‡é›†å™¨å®ä¾‹
twitter_collector = TwitterCollector()

