"""AIåˆ†æå¼•æ“ - ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ"""

from typing import Dict, List, Optional
from loguru import logger
from anthropic import Anthropic
from openai import OpenAI
from app.core.config import settings


class AIAnalyzer:
    """AIåˆ†æå™¨ - ä½¿ç”¨Claude/GPTè¿›è¡Œé¡¹ç›®åˆ†æ"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        self.claude_client = None
        self.openai_client = None
        
        # åˆå§‹åŒ–Claude
        if settings.ANTHROPIC_API_KEY:
            try:
                self.claude_client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)
                logger.info("âœ… Claude client initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize Claude: {e}")
        
        # åˆå§‹åŒ–OpenAI
        if settings.OPENAI_API_KEY:
            try:
                self.openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)
                logger.info("âœ… OpenAI client initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize OpenAI: {e}")
    
    def analyze_project_text(self, text: str, source: str = "twitter") -> Dict:
        """åˆ†æé¡¹ç›®æ–‡æœ¬å†…å®¹
        
        Args:
            text: é¡¹ç›®ç›¸å…³æ–‡æœ¬(æ¨æ–‡ã€å…¬å‘Šç­‰)
            source: æ¥æº(twitter, telegramç­‰)
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.claude_client and not self.openai_client:
            logger.warning("No AI client available, using mock analysis")
            return self._mock_analysis(text)
        
        prompt = f"""åˆ†æä»¥ä¸‹Web3é¡¹ç›®ç›¸å…³ä¿¡æ¯,æå–å…³é”®å†…å®¹:

æ¥æº: {source}
å†…å®¹: {text}

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æ:
1. é¡¹ç›®ç±»å‹ (DeFi/NFT/GameFi/Infrastructure/AIç­‰)
2. æ ¸å¿ƒåŠŸèƒ½/åˆ›æ–°ç‚¹
3. å›¢é˜Ÿä¿¡æ¯ (å¦‚æœæåˆ°)
4. èèµ„æƒ…å†µ (å¦‚æœæåˆ°)
5. æŠ€æœ¯ç‰¹ç‚¹
6. æ½œåœ¨é£é™©ç‚¹
7. æ•´ä½“è¯„ä»· (1-10åˆ†)

è¯·ç”¨JSONæ ¼å¼è¿”å›,åŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
  "category": "é¡¹ç›®åˆ†ç±»",
  "key_features": ["ç‰¹ç‚¹1", "ç‰¹ç‚¹2"],
  "team_info": "å›¢é˜Ÿä¿¡æ¯",
  "funding": "èèµ„ä¿¡æ¯",
  "tech_highlights": "æŠ€æœ¯äº®ç‚¹",
  "risks": ["é£é™©1", "é£é™©2"],
  "score_estimate": 8,
  "summary": "ä¸€å¥è¯æ€»ç»“"
}}
"""
        
        try:
            if self.claude_client:
                response = self.claude_client.messages.create(
                    model="claude-3-sonnet-20240229",
                    max_tokens=1000,
                    messages=[{"role": "user", "content": prompt}]
                )
                result_text = response.content[0].text
            else:
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.3
                )
                result_text = response.choices[0].message.content
            
            # è§£æJSON
            import json
            result = json.loads(result_text)
            logger.info(f"âœ… AI analysis completed: {result.get('category')}")
            return result
            
        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            return self._mock_analysis(text)
    
    def _mock_analysis(self, text: str) -> Dict:
        """æ¨¡æ‹ŸAIåˆ†æ(å½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨)"""
        return {
            "category": "DeFi",
            "key_features": [
                "è·¨é“¾æµåŠ¨æ€§èšåˆ",
                "ä½æ»‘ç‚¹äº¤æ˜“",
                "Gasä¼˜åŒ–"
            ],
            "team_info": "ç»éªŒä¸°å¯Œçš„å›¢é˜Ÿ",
            "funding": "æœªæŠ«éœ²",
            "tech_highlights": "åˆ›æ–°çš„AMMç®—æ³•",
            "risks": ["ä»£å¸ç»æµå­¦æœªå®Œå…¨å…¬å¼€"],
            "score_estimate": 7,
            "summary": "æœ‰æ½œåŠ›çš„DeFié¡¹ç›®,éœ€å…³æ³¨åç»­è¿›å±•"
        }
    
    def score_team_background(self, project_data: Dict) -> float:
        """è¯„ä¼°å›¢é˜ŸèƒŒæ™¯
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            å›¢é˜Ÿè¯„åˆ† (0-100)
        """
        score = 50.0  # åŸºç¡€åˆ†
        
        # å¦‚æœæœ‰æŠ•èµ„äººä¿¡æ¯
        if "funding" in project_data and project_data["funding"]:
            funding_text = project_data["funding"].lower()
            
            # é¡¶çº§VCåŠ åˆ†
            top_vcs = ["a16z", "paradigm", "coinbase ventures", "binance labs", "sequoia"]
            for vc in top_vcs:
                if vc in funding_text:
                    score += 10
                    logger.info(f"  +10åˆ†: é¡¶çº§VC {vc}")
        
        # å¦‚æœæœ‰å›¢é˜Ÿä¿¡æ¯
        if "team_info" in project_data and project_data["team_info"]:
            team_text = project_data["team_info"].lower()
            
            # çŸ¥åé¡¹ç›®èƒŒæ™¯
            if any(keyword in team_text for keyword in ["uniswap", "compound", "aave", "curve"]):
                score += 15
                logger.info("  +15åˆ†: æ¥è‡ªçŸ¥åé¡¹ç›®")
            
            # å…¬å¼€å›¢é˜Ÿ
            if "doxxed" in team_text or "å…¬å¼€" in team_text:
                score += 10
                logger.info("  +10åˆ†: å›¢é˜Ÿå…¬å¼€é€æ˜")
        
        # æ ¹æ®ä½œè€…å½±å“åŠ›è¯„åˆ†
        if "author" in project_data:
            followers = project_data["author"].get("followers", 0)
            if followers > 1000000:
                score += 15
                logger.info(f"  +15åˆ†: ä½œè€…ç²‰ä¸ {followers}")
            elif followers > 100000:
                score += 10
            elif followers > 10000:
                score += 5
        
        return min(score, 100)
    
    def score_technology(self, project_data: Dict) -> float:
        """è¯„ä¼°æŠ€æœ¯åˆ›æ–°
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            æŠ€æœ¯è¯„åˆ† (0-100)
        """
        score = 50.0
        
        # æŠ€æœ¯å…³é”®è¯åŠ åˆ†
        tech_keywords = {
            "zkp": 15, "zero-knowledge": 15, "zk": 15,
            "layer 2": 12, "l2": 12, "rollup": 12,
            "cross-chain": 10, "bridge": 10,
            "novel": 10, "innovative": 8, "revolutionary": 8,
            "audit": 10, "certik": 10, "peckshield": 10,
        }
        
        text = str(project_data).lower()
        for keyword, points in tech_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  +{points}åˆ†: æŠ€æœ¯å…³é”®è¯ '{keyword}'")
                break  # æ¯ä¸ªç±»åˆ«åªåŠ ä¸€æ¬¡åˆ†
        
        # GitHubæ´»è·ƒåº¦
        if "github_stars" in project_data:
            stars = project_data["github_stars"]
            if stars > 1000:
                score += 15
            elif stars > 500:
                score += 10
            elif stars > 100:
                score += 5
        
        return min(score, 100)
    
    def score_community(self, project_data: Dict) -> float:
        """è¯„ä¼°ç¤¾åŒºçƒ­åº¦
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            ç¤¾åŒºè¯„åˆ† (0-100)
        """
        score = 40.0
        
        # Twitteräº’åŠ¨æ•°æ®
        if "engagement" in project_data:
            eng = project_data["engagement"]
            
            likes = eng.get("likes", 0)
            retweets = eng.get("retweets", 0)
            
            # ç‚¹èµæ•°è¯„åˆ†
            if likes > 10000:
                score += 20
            elif likes > 5000:
                score += 15
            elif likes > 1000:
                score += 10
            elif likes > 100:
                score += 5
            
            # è½¬å‘æ•°è¯„åˆ†
            if retweets > 5000:
                score += 20
            elif retweets > 1000:
                score += 15
            elif retweets > 500:
                score += 10
            elif retweets > 50:
                score += 5
        
        # Telegramæ•°æ®
        if "telegram_members" in project_data:
            members = project_data["telegram_members"]
            if members > 50000:
                score += 15
            elif members > 10000:
                score += 10
            elif members > 1000:
                score += 5
        
        return min(score, 100)
    
    def score_tokenomics(self, project_data: Dict) -> float:
        """è¯„ä¼°ä»£å¸ç»æµå­¦
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            ä»£å¸ç»æµå­¦è¯„åˆ† (0-100)
        """
        score = 60.0  # åŸºç¡€åˆ†
        
        text = str(project_data).lower()
        
        # æ­£é¢å…³é”®è¯
        positive_keywords = {
            "fair launch": 15,
            "no presale": 10,
            "community": 8,
            "locked liquidity": 12,
            "vesting": 8,
        }
        
        for keyword, points in positive_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  +{points}åˆ†: ä»£å¸å…³é”®è¯ '{keyword}'")
        
        # è´Ÿé¢å…³é”®è¯
        negative_keywords = {
            "team holds": -10,
            "large allocation": -8,
        }
        
        for keyword, points in negative_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  {points}åˆ†: ä»£å¸é£é™© '{keyword}'")
        
        return max(min(score, 100), 0)
    
    def score_market_timing(self, project_data: Dict) -> float:
        """è¯„ä¼°å¸‚åœºæ—¶æœº
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            å¸‚åœºæ—¶æœºè¯„åˆ† (0-100)
        """
        score = 70.0  # åŸºç¡€åˆ†
        
        category = project_data.get("category", "").lower()
        
        # å½“å‰çƒ­é—¨èµ›é“åŠ åˆ†(å¯åŠ¨æ€è°ƒæ•´)
        hot_categories = {
            "defi": 10,
            "ai": 15,
            "gamefi": 8,
            "infrastructure": 12,
        }
        
        for cat, points in hot_categories.items():
            if cat in category:
                score += points
                logger.info(f"  +{points}åˆ†: çƒ­é—¨èµ›é“ '{cat}'")
                break
        
        return min(score, 100)
    
    def analyze_full_project(self, project_data: Dict) -> Dict:
        """å®Œæ•´åˆ†æé¡¹ç›®
        
        Args:
            project_data: é¡¹ç›®åŸå§‹æ•°æ®
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        logger.info(f"ğŸ” Starting full project analysis...")
        
        # 1. æ–‡æœ¬åˆ†æ
        text = project_data.get("text", "")
        ai_result = self.analyze_project_text(text, project_data.get("source", "unknown"))
        
        # åˆå¹¶AIåˆ†æç»“æœåˆ°é¡¹ç›®æ•°æ®
        enhanced_data = {**project_data, **ai_result}
        
        # 2. å„ç»´åº¦è¯„åˆ†
        scores = {
            "team": self.score_team_background(enhanced_data),
            "technology": self.score_technology(enhanced_data),
            "community": self.score_community(enhanced_data),
            "tokenomics": self.score_tokenomics(enhanced_data),
            "market_timing": self.score_market_timing(enhanced_data),
            "risk": 80.0,  # ç”±é£é™©æ£€æµ‹å™¨å•ç‹¬è®¡ç®—
        }
        
        logger.info(f"ğŸ“Š Individual scores: {scores}")
        
        # 3. è®¡ç®—ç»¼åˆè¯„åˆ†
        from app.services.analyzers.scorer import project_scorer
        
        overall_score = project_scorer.calculate_overall_score(
            team_score=scores["team"],
            tech_score=scores["technology"],
            community_score=scores["community"],
            tokenomics_score=scores["tokenomics"],
            market_timing_score=scores["market_timing"],
            risk_score=scores["risk"],
        )
        
        # 4. è®¡ç®—ç­‰çº§
        grade = project_scorer.calculate_grade(overall_score)
        
        logger.info(f"âœ… Analysis complete: Score={overall_score}, Grade={grade}")
        
        return {
            "overall_score": overall_score,
            "grade": grade,
            "scores": scores,
            "ai_analysis": ai_result,
            "category": ai_result.get("category"),
            "key_features": ai_result.get("key_features", []),
            "summary": ai_result.get("summary"),
        }


# å…¨å±€åˆ†æå™¨å®ä¾‹
ai_analyzer = AIAnalyzer()

