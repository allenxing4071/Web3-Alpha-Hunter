"""AIåˆ†æå¼•æ“ - ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ"""

from typing import Dict, List, Optional
from loguru import logger
from anthropic import Anthropic
from openai import OpenAI
from app.core.config import settings


class AIAnalyzer:
    """AIåˆ†æå™¨ - æ”¯æŒDeepSeek/Claude/GPT"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        self.deepseek_client = None
        self.claude_client = None
        self.openai_client = None
        self.active_provider = None
        
        # å°è¯•ä»æ•°æ®åº“åŠ è½½é…ç½®
        self._load_config_from_db()
        
        # å¦‚æœæ•°æ®åº“æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
        if not self.active_provider:
            self._load_config_from_env()
    
    def _load_config_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½AIé…ç½®"""
        try:
            from app.db.session import SessionLocal
            from app.models.ai_config import AIConfig
            from cryptography.fernet import Fernet
            import base64
            import hashlib
            
            # è§£å¯†å¯†é’¥
            ENCRYPTION_KEY = base64.urlsafe_b64encode(hashlib.sha256(b"web3-alpha-hunter-secret-key").digest())
            cipher_suite = Fernet(ENCRYPTION_KEY)
            
            db = SessionLocal()
            try:
                # è·å–æ‰€æœ‰å¯ç”¨çš„AIé…ç½®
                configs = db.query(AIConfig).filter(AIConfig.enabled == True).all()
                
                logger.info(f"ğŸ“‚ Found {len(configs)} enabled AI configs in database")
                
                for config in configs:
                    try:
                        # è§£å¯†APIå¯†é’¥
                        decrypted_key = cipher_suite.decrypt(config.api_key.encode()).decode()
                        
                        if config.name.lower() == "deepseek" and not self.active_provider:
                            self.deepseek_client = OpenAI(
                                api_key=decrypted_key,
                                base_url="https://api.deepseek.com"
                            )
                            self.active_provider = "deepseek"
                            logger.info(f"âœ… DeepSeek initialized from DB (model: {config.model})")
                        
                        elif config.name.lower() == "claude" and not self.active_provider:
                            self.claude_client = OpenAI(
                                api_key=decrypted_key,
                                base_url="https://api.gptsapi.net/v1"
                            )
                            self.active_provider = "claude"
                            logger.info(f"âœ… Claude initialized from DB (model: {config.model})")
                        
                        elif config.name.lower() == "openai" and not self.active_provider:
                            self.openai_client = OpenAI(
                                api_key=decrypted_key,
                                base_url="https://api.gptsapi.net/v1"
                            )
                            self.active_provider = "openai"
                            logger.info(f"âœ… OpenAI initialized from DB (model: {config.model})")
                    
                    except Exception as e:
                        logger.warning(f"Failed to initialize {config.name} from DB: {e}")
            finally:
                db.close()
        except Exception as e:
            logger.warning(f"Failed to load AI config from DB: {e}")
    
    def _load_config_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½AIé…ç½®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨DeepSeek (å›½å†…,ä¾¿å®œå¿«é€Ÿ)
        if settings.DEEPSEEK_API_KEY:
            try:
                self.deepseek_client = OpenAI(
                    api_key=settings.DEEPSEEK_API_KEY,
                    base_url="https://api.deepseek.com"
                )
                self.active_provider = "deepseek"
                logger.info("âœ… DeepSeek v3 client initialized from ENV (ä¼˜å…ˆä½¿ç”¨)")
            except Exception as e:
                logger.warning(f"Failed to initialize DeepSeek: {e}")
        
        # å¤‡ç”¨: Claude (é€šè¿‡ WildCard/GPTsAPI ä¸­è½¬,ä½¿ç”¨ OpenAI æ ¼å¼)
        if settings.ANTHROPIC_API_KEY and not self.active_provider:
            try:
                # WildCard çš„ Claude ä¹Ÿä½¿ç”¨ OpenAI å®¢æˆ·ç«¯æ ¼å¼
                self.claude_client = OpenAI(
                    api_key=settings.ANTHROPIC_API_KEY,
                    base_url="https://api.gptsapi.net/v1"
                )
                self.active_provider = "claude"
                logger.info("âœ… Claude client initialized from ENV (via GPTsAPI)")
            except Exception as e:
                logger.warning(f"Failed to initialize Claude: {e}")
        
        # å¤‡ç”¨: OpenAI (é€šè¿‡ WildCard/GPTsAPI ä¸­è½¬)
        if settings.OPENAI_API_KEY and not self.active_provider:
            try:
                self.openai_client = OpenAI(
                    api_key=settings.OPENAI_API_KEY,
                    base_url="https://api.gptsapi.net/v1"
                )
                self.active_provider = "openai"
                logger.info("âœ… OpenAI client initialized from ENV (via GPTsAPI)")
            except Exception as e:
                logger.warning(f"Failed to initialize OpenAI: {e}")
    
    def analyze_project_text(self, text: str, source: str = "twitter", retry_with_fallback: bool = True) -> Dict:
        """åˆ†æé¡¹ç›®æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒè‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨AIï¼‰

        Args:
            text: é¡¹ç›®ç›¸å…³æ–‡æœ¬(æ¨æ–‡ã€å…¬å‘Šç­‰)
            source: æ¥æº(twitter, telegramç­‰)
            retry_with_fallback: å¤±è´¥æ—¶æ˜¯å¦è‡ªåŠ¨å°è¯•å…¶ä»–AIæä¾›å•†

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.active_provider:
            logger.warning("No AI client available, using mock analysis")
            return self._mock_analysis(text)

        prompt = f"""åˆ†æä»¥ä¸‹Web3é¡¹ç›®ç›¸å…³ä¿¡æ¯,æä¾›ä¸“ä¸šè¯„ä¼°:

æ¥æº: {source}
å†…å®¹: {text}

è¯·åˆ†æå¹¶è¯„åˆ†(0-100åˆ†åˆ¶):
1. é¡¹ç›®ç±»å‹/åˆ†ç±»
2. å›¢é˜Ÿå®åŠ› (team_score)
3. æŠ€æœ¯åˆ›æ–° (tech_score)  
4. ç¤¾åŒºæ´»è·ƒåº¦ (community_score)
5. ä»£å¸ç»æµå­¦ (tokenomics_score)
6. å¸‚åœºæ—¶æœº (market_timing_score)
7. é£é™©è¯„ä¼° (risk_score, è¶Šä½è¶Šå¥½)

è¿”å›JSONæ ¼å¼(å¿…é¡»åŒ…å«æ‰€æœ‰å­—æ®µ):
{{
  "category": "DeFi/NFT/GameFi/Infrastructure/AI/Layer2",
  "overall_score": 75.0,
  "team_score": 70.0,
  "tech_score": 80.0,
  "community_score": 75.0,
  "tokenomics_score": 70.0,
  "market_timing_score": 80.0,
  "risk_score": 30.0,
  "grade": "A",
  "reasoning": "åˆ†æç†ç”±",
  "key_features": ["ç‰¹ç‚¹1", "ç‰¹ç‚¹2"],
  "risks": ["é£é™©1"],
  "summary": "ä¸€å¥è¯æ€»ç»“"
}}

è¯„åˆ†è§„åˆ™: overall_score>=90ä¸ºSçº§, >=80ä¸ºAçº§, >=70ä¸ºBçº§, >=60ä¸ºCçº§, <60ä¸ºDçº§
"""
        
        try:
            # ä¼˜å…ˆä½¿ç”¨DeepSeek v3
            if self.deepseek_client:
                response = self.deepseek_client.chat.completions.create(
                    model="deepseek-chat",  # è‡ªåŠ¨ä½¿ç”¨æœ€æ–°v3æ¨¡å‹
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯Web3é¡¹ç›®åˆ†æä¸“å®¶,æ“…é•¿ä»æ–‡æœ¬ä¸­æå–é¡¹ç›®å…³é”®ä¿¡æ¯ã€‚ä½ éœ€è¦å®¢è§‚ã€ä¸“ä¸šåœ°åˆ†æé¡¹ç›®,è¯†åˆ«æ½œåœ¨çš„æŠ•èµ„æœºä¼šå’Œé£é™©ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2048,  # v3æ”¯æŒæ›´é•¿è¾“å‡º
                    temperature=0.7,
                    top_p=0.95,
                    stream=False
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… DeepSeek v3 analysis completed")
            
            # å¤‡ç”¨: Claude (é€šè¿‡ WildCard,ä½¿ç”¨ OpenAI æ ¼å¼)
            elif self.claude_client:
                response = self.claude_client.chat.completions.create(
                    model="claude-3-5-sonnet-20241022",  # WildCard æ”¯æŒçš„ Claude æ¨¡å‹
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯Web3é¡¹ç›®åˆ†æä¸“å®¶,æ“…é•¿ä»æ–‡æœ¬ä¸­æå–é¡¹ç›®å…³é”®ä¿¡æ¯ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2048,
                    temperature=0.7
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… Claude analysis completed (via GPTsAPI)")
            
            # å¤‡ç”¨: OpenAI
            elif self.openai_client:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1024,
                    temperature=0.7
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… OpenAI analysis completed")
            else:
                logger.warning("No AI provider available")
                return self._mock_analysis(text)
            
            # è§£æJSONï¼ˆå¤„ç†Markdownä»£ç å—ï¼‰
            import json
            import re
            
            # ç§»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
            if "```json" in result_text:
                # æå–```jsonå’Œ```ä¹‹é—´çš„å†…å®¹
                match = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
                if match:
                    result_text = match.group(1)
            elif "```" in result_text:
                # æå–```å’Œ```ä¹‹é—´çš„å†…å®¹
                match = re.search(r'```\s*(.*?)\s*```', result_text, re.DOTALL)
                if match:
                    result_text = match.group(1)
            
            result_text = result_text.strip()
            
            # å°è¯•è§£æJSON
            try:
                result = json.loads(result_text)
                logger.info(f"âœ… AI analysis completed: {result.get('category', 'Unknown')}")
                return result
            except json.JSONDecodeError as je:
                logger.error(f"JSONè§£æå¤±è´¥: {je}")
                logger.error(f"åŸå§‹å“åº”: {result_text[:500]}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                return self._extract_from_text(result_text, text)
            
        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            return self._mock_analysis(text)
    
    def _extract_from_text(self, ai_response: str, original_text: str) -> Dict:
        """ä»AIæ–‡æœ¬å“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
        # åŸºç¡€ç»“æ„
        result = {
            "category": "Unknown",
            "key_features": [],
            "team_info": "",
            "funding": "",
            "tech_highlights": "",
            "risks": [],
            "score_estimate": 5,
            "summary": ai_response[:200] if ai_response else "AIåˆ†æå¤±è´¥",
            "overall_score": 50.0,
            "team_score": 50.0,
            "tech_score": 50.0,
            "community_score": 50.0,
            "tokenomics_score": 50.0,
            "market_timing_score": 50.0,
            "risk_score": 50.0,
            "grade": "C",
            "reasoning": ai_response[:500] if ai_response else "æ— æ³•ç”Ÿæˆåˆ†æ"
        }
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–åˆ†ç±»
        categories = ["DeFi", "NFT", "GameFi", "Infrastructure", "AI", "Layer2", "DEX"]
        for cat in categories:
            if cat.lower() in ai_response.lower() or cat.lower() in original_text.lower():
                result["category"] = cat
                break
        
        return result
    
    def _mock_analysis(self, text: str) -> Dict:
        """æ¨¡æ‹ŸAIåˆ†æ(å½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨)"""
        return {
            "category": "DeFi",
            "key_features": [
                "è·¨é“¾æµåŠ¨æ€§èšåˆ",
                "ä½æ»‘ç‚¹äº¤æ˜“",
                "Gasä¼˜åŒ–"
            ],
            "team_info": "ç»éªŒä¸°å¯Œçš„å›¢é˜Ÿ",
            "funding": "æœªæŠ«éœ²",
            "tech_highlights": "åˆ›æ–°çš„AMMç®—æ³•",
            "risks": ["ä»£å¸ç»æµå­¦æœªå®Œå…¨å…¬å¼€"],
            "score_estimate": 7,
            "summary": "æœ‰æ½œåŠ›çš„DeFié¡¹ç›®,éœ€å…³æ³¨åç»­è¿›å±•"
        }
    
    def score_team_background(self, project_data: Dict) -> float:
        """è¯„ä¼°å›¢é˜ŸèƒŒæ™¯
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            å›¢é˜Ÿè¯„åˆ† (0-100)
        """
        score = 50.0  # åŸºç¡€åˆ†
        
        # å¦‚æœæœ‰æŠ•èµ„äººä¿¡æ¯
        if "funding" in project_data and project_data["funding"]:
            funding_text = project_data["funding"].lower()
            
            # é¡¶çº§VCåŠ åˆ†
            top_vcs = ["a16z", "paradigm", "coinbase ventures", "binance labs", "sequoia"]
            for vc in top_vcs:
                if vc in funding_text:
                    score += 10
                    logger.info(f"  +10åˆ†: é¡¶çº§VC {vc}")
        
        # å¦‚æœæœ‰å›¢é˜Ÿä¿¡æ¯
        if "team_info" in project_data and project_data["team_info"]:
            team_text = project_data["team_info"].lower()
            
            # çŸ¥åé¡¹ç›®èƒŒæ™¯
            if any(keyword in team_text for keyword in ["uniswap", "compound", "aave", "curve"]):
                score += 15
                logger.info("  +15åˆ†: æ¥è‡ªçŸ¥åé¡¹ç›®")
            
            # å…¬å¼€å›¢é˜Ÿ
            if "doxxed" in team_text or "å…¬å¼€" in team_text:
                score += 10
                logger.info("  +10åˆ†: å›¢é˜Ÿå…¬å¼€é€æ˜")
        
        # æ ¹æ®ä½œè€…å½±å“åŠ›è¯„åˆ†
        if "author" in project_data:
            followers = project_data["author"].get("followers", 0)
            if followers > 1000000:
                score += 15
                logger.info(f"  +15åˆ†: ä½œè€…ç²‰ä¸ {followers}")
            elif followers > 100000:
                score += 10
            elif followers > 10000:
                score += 5
        
        return min(score, 100)
    
    def score_technology(self, project_data: Dict) -> float:
        """è¯„ä¼°æŠ€æœ¯åˆ›æ–°
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            æŠ€æœ¯è¯„åˆ† (0-100)
        """
        score = 50.0
        
        # æŠ€æœ¯å…³é”®è¯åŠ åˆ†
        tech_keywords = {
            "zkp": 15, "zero-knowledge": 15, "zk": 15,
            "layer 2": 12, "l2": 12, "rollup": 12,
            "cross-chain": 10, "bridge": 10,
            "novel": 10, "innovative": 8, "revolutionary": 8,
            "audit": 10, "certik": 10, "peckshield": 10,
        }
        
        text = str(project_data).lower()
        for keyword, points in tech_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  +{points}åˆ†: æŠ€æœ¯å…³é”®è¯ '{keyword}'")
                break  # æ¯ä¸ªç±»åˆ«åªåŠ ä¸€æ¬¡åˆ†
        
        # GitHubæ´»è·ƒåº¦
        if "github_stars" in project_data:
            stars = project_data["github_stars"]
            if stars > 1000:
                score += 15
            elif stars > 500:
                score += 10
            elif stars > 100:
                score += 5
        
        return min(score, 100)
    
    def score_community(self, project_data: Dict) -> float:
        """è¯„ä¼°ç¤¾åŒºçƒ­åº¦
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            ç¤¾åŒºè¯„åˆ† (0-100)
        """
        score = 40.0
        
        # Twitteräº’åŠ¨æ•°æ®
        if "engagement" in project_data:
            eng = project_data["engagement"]
            
            likes = eng.get("likes", 0)
            retweets = eng.get("retweets", 0)
            
            # ç‚¹èµæ•°è¯„åˆ†
            if likes > 10000:
                score += 20
            elif likes > 5000:
                score += 15
            elif likes > 1000:
                score += 10
            elif likes > 100:
                score += 5
            
            # è½¬å‘æ•°è¯„åˆ†
            if retweets > 5000:
                score += 20
            elif retweets > 1000:
                score += 15
            elif retweets > 500:
                score += 10
            elif retweets > 50:
                score += 5
        
        # Telegramæ•°æ®
        if "telegram_members" in project_data:
            members = project_data["telegram_members"]
            if members > 50000:
                score += 15
            elif members > 10000:
                score += 10
            elif members > 1000:
                score += 5
        
        return min(score, 100)
    
    def score_tokenomics(self, project_data: Dict) -> float:
        """è¯„ä¼°ä»£å¸ç»æµå­¦
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            ä»£å¸ç»æµå­¦è¯„åˆ† (0-100)
        """
        score = 60.0  # åŸºç¡€åˆ†
        
        text = str(project_data).lower()
        
        # æ­£é¢å…³é”®è¯
        positive_keywords = {
            "fair launch": 15,
            "no presale": 10,
            "community": 8,
            "locked liquidity": 12,
            "vesting": 8,
        }
        
        for keyword, points in positive_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  +{points}åˆ†: ä»£å¸å…³é”®è¯ '{keyword}'")
        
        # è´Ÿé¢å…³é”®è¯
        negative_keywords = {
            "team holds": -10,
            "large allocation": -8,
        }
        
        for keyword, points in negative_keywords.items():
            if keyword in text:
                score += points
                logger.info(f"  {points}åˆ†: ä»£å¸é£é™© '{keyword}'")
        
        return max(min(score, 100), 0)
    
    def score_market_timing(self, project_data: Dict) -> float:
        """è¯„ä¼°å¸‚åœºæ—¶æœº
        
        Args:
            project_data: é¡¹ç›®æ•°æ®
            
        Returns:
            å¸‚åœºæ—¶æœºè¯„åˆ† (0-100)
        """
        score = 70.0  # åŸºç¡€åˆ†
        
        category = project_data.get("category", "").lower()
        
        # å½“å‰çƒ­é—¨èµ›é“åŠ åˆ†(å¯åŠ¨æ€è°ƒæ•´)
        hot_categories = {
            "defi": 10,
            "ai": 15,
            "gamefi": 8,
            "infrastructure": 12,
        }
        
        for cat, points in hot_categories.items():
            if cat in category:
                score += points
                logger.info(f"  +{points}åˆ†: çƒ­é—¨èµ›é“ '{cat}'")
                break
        
        return min(score, 100)
    
    def generate_detailed_analysis(self, project_data: Dict) -> Dict:
        """ç”Ÿæˆè¯¦ç»†AIåˆ†æï¼ˆåŸºäºçœŸå®æ•°æ®ï¼Œé¿å…è™šå‡ä¿¡æ¯ï¼‰

        Args:
            project_data: é¡¹ç›®å®Œæ•´æ•°æ®ï¼ˆåŒ…å«çœŸå®æŒ‡æ ‡ï¼‰

        Returns:
            è¯¦ç»†åˆ†æç»“æœï¼ˆsummary, key_features, investment_suggestionç­‰ï¼‰
        """
        logger.info(f"ğŸ” Generating detailed AI analysis for {project_data.get('name', 'Unknown')}...")

        if not self.active_provider:
            logger.warning("No AI client available")
            return self._mock_detailed_analysis()

        # æ„å»ºåŸºäºçœŸå®æ•°æ®çš„prompt
        project_name = project_data.get("name", "Unknown")
        description = project_data.get("description", "æ— æè¿°")
        category = project_data.get("category", "Unknown")
        blockchain = project_data.get("blockchain", "Unknown")

        # æå–çœŸå®æŒ‡æ ‡
        metrics = project_data.get("metrics", {})
        twitter_followers = metrics.get("twitter_followers", 0)
        telegram_members = metrics.get("telegram_members", 0)
        github_stars = metrics.get("github_stars", 0)

        # è¯„åˆ†æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        scores = project_data.get("scores", {})
        overall_score = scores.get("overall", 0)

        prompt = f"""ä½ æ˜¯Web3é¡¹ç›®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹**çœŸå®æ•°æ®**åˆ†æé¡¹ç›®ï¼Œä¸¥ç¦ç¼–é€ ä»»ä½•ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚

**é¡¹ç›®ä¿¡æ¯ï¼ˆçœŸå®æ•°æ®ï¼‰ï¼š**
- é¡¹ç›®åç§°: {project_name}
- åˆ†ç±»: {category}
- åŒºå—é“¾: {blockchain}
- æè¿°: {description}

**ç¤¾äº¤åª’ä½“æ•°æ®ï¼ˆçœŸå®æŒ‡æ ‡ï¼‰ï¼š**
- Twitterç²‰ä¸: {twitter_followers if twitter_followers > 0 else "æœªçŸ¥"}
- Telegramæˆå‘˜: {telegram_members if telegram_members > 0 else "æœªçŸ¥"}
- GitHub Stars: {github_stars if github_stars > 0 else "æœªçŸ¥"}

**è¯„åˆ†ï¼š**
- ç»¼åˆè¯„åˆ†: {overall_score}/100

**åˆ†æè¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
1. åªåŸºäºä¸Šè¿°çœŸå®æ•°æ®è¿›è¡Œåˆ†æ
2. å¦‚æœæŸé¡¹æ•°æ®ç¼ºå¤±ï¼Œæ˜ç¡®è¯´æ˜"æ•°æ®ä¸è¶³"ï¼Œä¸è¦ç¼–é€ 
3. æŠ€æœ¯ç‰¹æ€§åªæè¿°è¯¥é¡¹ç›®ç±»å‹çš„é€šç”¨ç‰¹å¾ï¼Œä¸ç¼–é€ å…·ä½“æŠ€æœ¯ç»†èŠ‚
4. æŠ•èµ„å»ºè®®è¦ä¿å®ˆè°¨æ…ï¼Œå¼ºè°ƒé£é™©

è¯·è¿”å›JSONæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆæ ¼å¼ï¼‰ï¼š
{{
  "summary": "100-150å­—çš„é¡¹ç›®æ‘˜è¦ï¼ŒåªåŸºäºå·²çŸ¥ä¿¡æ¯",
  "key_features": [
    "ç‰¹æ€§1ï¼ˆåŸºäºçœŸå®ç±»å‹ç‰¹å¾ï¼‰",
    "ç‰¹æ€§2",
    "ç‰¹æ€§3",
    "ç‰¹æ€§4",
    "ç‰¹æ€§5"
  ],
  "investment_suggestion": {{
    "action": "æŠ•èµ„å»ºè®®æ–‡å­—ï¼ˆ80-120å­—ï¼Œå¼ºè°ƒé£é™©å’Œæ•°æ®ä¸è¶³ï¼‰",
    "position_size": "å»ºè®®ä»“ä½ï¼ˆå¦‚ï¼š1-3%ï¼‰",
    "entry_timing": "å…¥åœºæ—¶æœºå»ºè®®",
    "stop_loss": æ­¢æŸç™¾åˆ†æ¯”æ•°å­—ï¼ˆå¦‚ï¼š25ï¼‰
  }}
}}

**é‡è¦æé†’ï¼šä¸è¦ç¼–é€ å›¢é˜Ÿæˆå‘˜ã€èèµ„ä¿¡æ¯ã€åˆä½œä¼™ä¼´ç­‰æœªæä¾›çš„æ•°æ®ï¼**"""

        try:
            # è°ƒç”¨AIï¼ˆä¼˜å…ˆDeepSeekï¼‰
            if self.deepseek_client:
                response = self.deepseek_client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„Web3åˆ†æå¸ˆã€‚ä½ å¿…é¡»åªåŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡Œåˆ†æï¼Œä¸¥ç¦ç¼–é€ ä»»ä½•ä¿¡æ¯ã€‚å¦‚æœæ•°æ®ä¸è¶³ï¼Œå¿…é¡»æ˜ç¡®è¯´æ˜ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2048,
                    temperature=0.3,  # é™ä½æ¸©åº¦ï¼Œå‡å°‘åˆ›é€ æ€§ï¼Œå¢åŠ å‡†ç¡®æ€§
                    top_p=0.9,
                    stream=False
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… DeepSeek detailed analysis generated")

            elif self.claude_client:
                response = self.claude_client.chat.completions.create(
                    model="claude-3-5-sonnet-20241022",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„Web3åˆ†æå¸ˆã€‚å¿…é¡»åªåŸºäºçœŸå®æ•°æ®åˆ†æï¼Œä¸ç¼–é€ ä¿¡æ¯ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2048,
                    temperature=0.3
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… Claude detailed analysis generated")

            elif self.openai_client:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„Web3åˆ†æå¸ˆã€‚åªåŸºäºçœŸå®æ•°æ®åˆ†æã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1500,
                    temperature=0.3
                )
                result_text = response.choices[0].message.content
                logger.info(f"âœ… OpenAI detailed analysis generated")
            else:
                logger.warning("No AI provider available")
                return self._mock_detailed_analysis()

            # è§£æJSON
            import json
            import re

            # ç§»é™¤Markdownä»£ç å—
            if "```json" in result_text:
                match = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
                if match:
                    result_text = match.group(1)
            elif "```" in result_text:
                match = re.search(r'```\s*(.*?)\s*```', result_text, re.DOTALL)
                if match:
                    result_text = match.group(1)

            result_text = result_text.strip()
            result = json.loads(result_text)

            logger.info(f"âœ… Detailed analysis parsed successfully")
            return result

        except Exception as e:
            logger.error(f"âŒ Failed to generate detailed analysis: {e}")
            return self._mock_detailed_analysis()

    def _mock_detailed_analysis(self) -> Dict:
        """æ¨¡æ‹Ÿè¯¦ç»†åˆ†æï¼ˆå½“AIä¸å¯ç”¨æ—¶ï¼‰"""
        return {
            "summary": "æš‚æ— è¯¦ç»†åˆ†ææ‘˜è¦ï¼ŒAIæœåŠ¡ä¸å¯ç”¨",
            "key_features": [
                "æ•°æ®é‡‡é›†ä¸­",
                "åˆ†æç”Ÿæˆä¸­",
                "è¯·ç¨åæŸ¥çœ‹"
            ],
            "investment_suggestion": {
                "action": "æ•°æ®ä¸è¶³ï¼Œæš‚æ— æŠ•èµ„å»ºè®®",
                "position_size": "0%",
                "entry_timing": "ç­‰å¾…æ›´å¤šæ•°æ®",
                "stop_loss": 0
            }
        }

    def analyze_full_project(self, project_data: Dict) -> Dict:
        """å®Œæ•´åˆ†æé¡¹ç›®

        Args:
            project_data: é¡¹ç›®åŸå§‹æ•°æ®

        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        logger.info(f"ğŸ” Starting full project analysis...")

        # 1. æ–‡æœ¬åˆ†æ
        text = project_data.get("text", "")
        ai_result = self.analyze_project_text(text, project_data.get("source", "unknown"))

        # åˆå¹¶AIåˆ†æç»“æœåˆ°é¡¹ç›®æ•°æ®
        enhanced_data = {**project_data, **ai_result}

        # 2. å„ç»´åº¦è¯„åˆ†
        scores = {
            "team": self.score_team_background(enhanced_data),
            "technology": self.score_technology(enhanced_data),
            "community": self.score_community(enhanced_data),
            "tokenomics": self.score_tokenomics(enhanced_data),
            "market_timing": self.score_market_timing(enhanced_data),
            "risk": 80.0,  # ç”±é£é™©æ£€æµ‹å™¨å•ç‹¬è®¡ç®—
        }

        logger.info(f"ğŸ“Š Individual scores: {scores}")

        # 3. è®¡ç®—ç»¼åˆè¯„åˆ†
        from app.services.analyzers.scorer import project_scorer

        overall_score = project_scorer.calculate_overall_score(
            team_score=scores["team"],
            tech_score=scores["technology"],
            community_score=scores["community"],
            tokenomics_score=scores["tokenomics"],
            market_timing_score=scores["market_timing"],
            risk_score=scores["risk"],
        )

        # 4. è®¡ç®—ç­‰çº§
        grade = project_scorer.calculate_grade(overall_score)

        logger.info(f"âœ… Analysis complete: Score={overall_score}, Grade={grade}")

        return {
            "overall_score": overall_score,
            "grade": grade,
            "scores": scores,
            "ai_analysis": ai_result,
            "category": ai_result.get("category"),
            "key_features": ai_result.get("key_features", []),
            "summary": ai_result.get("summary"),
        }


# å…¨å±€åˆ†æå™¨å®ä¾‹
ai_analyzer = AIAnalyzer()

