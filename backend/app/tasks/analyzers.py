"""AIåˆ†æä»»åŠ¡"""

from loguru import logger
from app.tasks.celery_app import celery_app
from app.db import SessionLocal
from app.models import Project, AIAnalysis
from app.services.analyzers import ai_analyzer
from sqlalchemy import and_


@celery_app.task(name="app.tasks.analyzers.analyze_new_projects")
def analyze_new_projects():
    """åˆ†ææ–°å‘ç°çš„é¡¹ç›®"""
    logger.info("ğŸ¤– Starting AI analysis for new projects...")
    
    try:
        db = SessionLocal()
        
        # æŸ¥æ‰¾æœªåˆ†æçš„é¡¹ç›®ï¼ˆæ¯æ¬¡å¤„ç†50ä¸ªï¼‰
        projects = db.query(Project).filter(
            and_(
                Project.status == 'discovered',
                Project.overall_score == None
            )
        ).limit(50).all()
        
        if not projects:
            logger.info("â„¹ï¸ No new projects to analyze")
            return {"success": True, "analyzed": 0}
        
        logger.info(f"ğŸ“Š Found {len(projects)} projects to analyze")
        
        analyzed_count = 0
        for project in projects:
            try:
                # æ„å»ºé¡¹ç›®æè¿°æ–‡æœ¬
                project_text = f"""
é¡¹ç›®åç§°: {project.project_name}
ç¬¦å·: {project.symbol or 'N/A'}
æè¿°: {project.description or 'N/A'}
æ¥æº: {project.discovered_from}
Twitter: {project.twitter_handle or 'N/A'}
"""

                # 1. è°ƒç”¨AIè¯„åˆ†åˆ†æ
                score_result = ai_analyzer.analyze_project_text(
                    text=project_text,
                    source=project.discovered_from or 'unknown'
                )

                if not score_result or not score_result.get('overall_score'):
                    logger.warning(f"âš ï¸ Failed to analyze {project.project_name}: No score returned")
                    continue

                # æ›´æ–°é¡¹ç›®è¯„åˆ†
                project.overall_score = score_result.get('overall_score')
                project.team_score = score_result.get('team_score')
                project.tech_score = score_result.get('tech_score')
                project.community_score = score_result.get('community_score')
                project.tokenomics_score = score_result.get('tokenomics_score')
                project.market_timing_score = score_result.get('market_timing_score')
                project.risk_score = score_result.get('risk_score')
                project.grade = score_result.get('grade')
                project.category = score_result.get('category', project.category)
                project.status = 'analyzed'

                # 2. ç”Ÿæˆè¯¦ç»†AIåˆ†æï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰
                from datetime import datetime
                from sqlalchemy import text

                # è·å–é¡¹ç›®çš„çœŸå®æŒ‡æ ‡æ•°æ®
                metrics_query = text("""
                    SELECT
                        COALESCE(sm.twitter_followers, 0) as twitter_followers,
                        COALESCE(sm.telegram_members, 0) as telegram_members,
                        COALESCE(sm.github_stars, 0) as github_stars
                    FROM projects p
                    LEFT JOIN social_metrics sm ON sm.project_id = p.id
                    WHERE p.id = :project_id
                    ORDER BY sm.snapshot_time DESC
                    LIMIT 1
                """)

                metrics_result = db.execute(metrics_query, {"project_id": project.id}).fetchone()

                project_data_for_ai = {
                    "name": project.project_name,
                    "description": project.description or "æš‚æ— æè¿°",
                    "category": project.category or "Unknown",
                    "blockchain": project.blockchain or "Unknown",
                    "metrics": {
                        "twitter_followers": metrics_result[0] if metrics_result else 0,
                        "telegram_members": metrics_result[1] if metrics_result else 0,
                        "github_stars": metrics_result[2] if metrics_result else 0,
                    },
                    "scores": {
                        "overall": project.overall_score,
                        "team": project.team_score,
                        "tech": project.tech_score,
                        "community": project.community_score,
                    }
                }

                detailed_analysis = ai_analyzer.generate_detailed_analysis(project_data_for_ai)

                # 3. ä¿å­˜è¯¦ç»†AIåˆ†æåˆ°ai_analysisè¡¨
                existing_analysis = db.query(AIAnalysis).filter(
                    AIAnalysis.project_id == project.id
                ).first()

                if existing_analysis:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    existing_analysis.whitepaper_summary = detailed_analysis.get('summary', '')
                    existing_analysis.key_features = detailed_analysis.get('key_features', [])
                    existing_analysis.similar_projects = []  # æš‚æ—¶ä¸ºç©º
                    existing_analysis.sentiment_score = 0.75
                    existing_analysis.sentiment_label = 'positive'
                    existing_analysis.risk_flags = []
                    existing_analysis.scam_probability = 5.0
                    existing_analysis.investment_suggestion = detailed_analysis.get('investment_suggestion', {}).get('action', '')
                    existing_analysis.position_size = detailed_analysis.get('investment_suggestion', {}).get('position_size', '')
                    existing_analysis.entry_timing = detailed_analysis.get('investment_suggestion', {}).get('entry_timing', '')
                    existing_analysis.stop_loss_percentage = detailed_analysis.get('investment_suggestion', {}).get('stop_loss', 0)
                    existing_analysis.analyzed_at = datetime.utcnow()
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    ai_analysis = AIAnalysis(
                        project_id=project.id,
                        whitepaper_summary=detailed_analysis.get('summary', ''),
                        key_features=detailed_analysis.get('key_features', []),
                        similar_projects=[],
                        sentiment_score=0.75,
                        sentiment_label='positive',
                        risk_flags=[],
                        scam_probability=5.0,
                        investment_suggestion=detailed_analysis.get('investment_suggestion', {}).get('action', ''),
                        position_size=detailed_analysis.get('investment_suggestion', {}).get('position_size', ''),
                        entry_timing=detailed_analysis.get('investment_suggestion', {}).get('entry_timing', ''),
                        stop_loss_percentage=detailed_analysis.get('investment_suggestion', {}).get('stop_loss', 0),
                        analyzed_at=datetime.utcnow()
                    )
                    db.add(ai_analysis)

                analyzed_count += 1
                logger.info(f"âœ… Analyzed {project.project_name}: Grade {project.grade}, Score {project.overall_score:.1f}")
                logger.info(f"   ğŸ“ Summary: {detailed_analysis.get('summary', '')[:80]}...")

            except Exception as e:
                logger.error(f"âŒ Error analyzing project {project.id}: {e}")
                import traceback
                logger.error(traceback.format_exc())
                continue
        
        db.commit()
        db.close()
        
        logger.info(f"ğŸ‰ AI analysis completed: {analyzed_count}/{len(projects)} projects analyzed")
        
        return {
            "success": True,
            "analyzed": analyzed_count,
            "total": len(projects)
        }
        
    except Exception as e:
        logger.error(f"âŒ AI analysis task failed: {e}")
        return {"success": False, "error": str(e)}


@celery_app.task(name="app.tasks.analyzers.update_all_scores")
def update_all_scores():
    """æ›´æ–°æ‰€æœ‰é¡¹ç›®è¯„åˆ†ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰"""
    logger.info("ğŸ”„ Starting periodic score update...")
    
    try:
        db = SessionLocal()
        
        # æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„é¡¹ç›®ï¼ˆå·²åˆ†æä½†è¯„åˆ†è¾ƒæ—§çš„ï¼‰
        projects = db.query(Project).filter(
            Project.status == 'analyzed'
        ).order_by(
            Project.last_updated_at.asc()
        ).limit(20).all()
        
        if not projects:
            logger.info("â„¹ï¸ No projects to update")
            return {"success": True, "updated": 0}
        
        updated_count = 0
        for project in projects:
            try:
                # æ„å»ºé¡¹ç›®æè¿°æ–‡æœ¬
                project_text = f"""
é¡¹ç›®åç§°: {project.project_name}
ç¬¦å·: {project.symbol or 'N/A'}
æè¿°: {project.description or 'N/A'}
æ¥æº: {project.discovered_from}
"""
                
                # é‡æ–°åˆ†æ
                result = ai_analyzer.analyze_project_text(
                    text=project_text,
                    source=project.discovered_from or 'unknown'
                )
                
                if result and result.get('overall_score'):
                    project.overall_score = result.get('overall_score')
                    project.grade = result.get('grade')
                    updated_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ Error updating project {project.id}: {e}")
                continue
        
        db.commit()
        db.close()
        
        logger.info(f"âœ… Score update completed: {updated_count} projects updated")
        
        return {
            "success": True,
            "updated": updated_count
        }
        
    except Exception as e:
        logger.error(f"âŒ Score update failed: {e}")
        return {"success": False, "error": str(e)}

